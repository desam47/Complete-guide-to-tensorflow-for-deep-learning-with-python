{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.pieriandata.com\"><img src=\"../Pierian_Data_Logo.PNG\"></a>\n",
    "<strong><center>Copyright by Pierian Data Inc.</center></strong> \n",
    "<strong><center>Created by Jose Marcial Portilla.</center></strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEPLOYMENT\n",
    "\n",
    "**Welcome to deployment section! In this section of the course, we will go through the entire deployment process, starting as if you had to create a servicable model from scratch, then deploy it for others to use, either through API or a web form.**\n",
    "\n",
    "# Data\n",
    "\n",
    "For this example we use the very common data set: [iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set), which is about flowers. \n",
    "\n",
    "From Wikipedia:\n",
    "The Iris flower data set or Fisher's Iris data set is a multivariate data set introduced by the British statistician and biologist Ronald Fisher in his 1936 paper The use of multiple measurements in taxonomic problems as an example of linear discriminant analysis.[1] It is sometimes called Anderson's Iris data set because Edgar Anderson collected the data to quantify the morphologic variation of Iris flowers of three related species.[2] Two of the three species were collected in the Gasp√© Peninsula \"all from the same pasture, and picked on the same day and measured at the same time by the same person with the same apparatus\".[3]\n",
    "\n",
    "The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:15:57.667478Z",
     "start_time": "2020-05-06T20:15:57.663644Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:15:57.820716Z",
     "start_time": "2020-05-06T20:15:57.812757Z"
    }
   },
   "outputs": [],
   "source": [
    "iris = pd.read_csv(\"../DATA/iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:15:57.957743Z",
     "start_time": "2020-05-06T20:15:57.939330Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:15:58.354972Z",
     "start_time": "2020-05-06T20:15:58.348374Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width',\n",
       "       'species'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:15:58.525767Z",
     "start_time": "2020-05-06T20:15:58.520533Z"
    }
   },
   "outputs": [],
   "source": [
    "X = iris.drop('species',axis=1)\n",
    "y = iris['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:15:58.642461Z",
     "start_time": "2020-05-06T20:15:58.638433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:15:58.778621Z",
     "start_time": "2020-05-06T20:15:58.775430Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lots of ways to one hot encode\n",
    "# https://stackoverflow.com/questions/47573293/unable-to-transform-string-column-to-categorical-matrix-using-keras-and-sklearn\n",
    "# https://stackoverflow.com/questions/35107559/one-hot-encoding-of-string-categorical-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:15:58.921660Z",
     "start_time": "2020-05-06T20:15:58.917208Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()\n",
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:15:59.061571Z",
     "start_time": "2020-05-06T20:15:59.057335Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:15:59.221303Z",
     "start_time": "2020-05-06T20:15:59.214364Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:15:59.923352Z",
     "start_time": "2020-05-06T20:15:59.912968Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:16:00.428086Z",
     "start_time": "2020-05-06T20:16:00.411818Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:16:00.945272Z",
     "start_time": "2020-05-06T20:16:00.925961Z"
    }
   },
   "outputs": [],
   "source": [
    "scaled_X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:16:01.472845Z",
     "start_time": "2020-05-06T20:16:01.457252Z"
    }
   },
   "outputs": [],
   "source": [
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "\n",
    "### Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:16:03.496701Z",
     "start_time": "2020-05-06T20:16:03.489029Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:16:04.424433Z",
     "start_time": "2020-05-06T20:16:04.339816Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=4,activation='relu',input_shape=[4,]))\n",
    "\n",
    "# Last layer for multi-class classification of 3 species\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:16:06.690896Z",
     "start_time": "2020-05-06T20:16:06.677431Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:16:07.574362Z",
     "start_time": "2020-05-06T20:16:07.569715Z"
    }
   },
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:16:15.373267Z",
     "start_time": "2020-05-06T20:16:08.631711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/300\n",
      "120/120 [==============================] - 0s 3ms/sample - loss: 1.1322 - accuracy: 0.3167 - val_loss: 1.1471 - val_accuracy: 0.4000\n",
      "Epoch 2/300\n",
      "120/120 [==============================] - 0s 126us/sample - loss: 1.1254 - accuracy: 0.3167 - val_loss: 1.1412 - val_accuracy: 0.4000\n",
      "Epoch 3/300\n",
      "120/120 [==============================] - 0s 234us/sample - loss: 1.1182 - accuracy: 0.3167 - val_loss: 1.1351 - val_accuracy: 0.4000\n",
      "Epoch 4/300\n",
      "120/120 [==============================] - 0s 176us/sample - loss: 1.1112 - accuracy: 0.3167 - val_loss: 1.1291 - val_accuracy: 0.4000\n",
      "Epoch 5/300\n",
      "120/120 [==============================] - 0s 180us/sample - loss: 1.1043 - accuracy: 0.3167 - val_loss: 1.1232 - val_accuracy: 0.4000\n",
      "Epoch 6/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 1.0979 - accuracy: 0.3167 - val_loss: 1.1175 - val_accuracy: 0.4000\n",
      "Epoch 7/300\n",
      "120/120 [==============================] - 0s 219us/sample - loss: 1.0913 - accuracy: 0.3083 - val_loss: 1.1118 - val_accuracy: 0.3667\n",
      "Epoch 8/300\n",
      "120/120 [==============================] - 0s 188us/sample - loss: 1.0850 - accuracy: 0.3083 - val_loss: 1.1061 - val_accuracy: 0.3667\n",
      "Epoch 9/300\n",
      "120/120 [==============================] - 0s 203us/sample - loss: 1.0791 - accuracy: 0.3083 - val_loss: 1.1005 - val_accuracy: 0.3667\n",
      "Epoch 10/300\n",
      "120/120 [==============================] - 0s 176us/sample - loss: 1.0727 - accuracy: 0.3583 - val_loss: 1.0950 - val_accuracy: 0.4333\n",
      "Epoch 11/300\n",
      "120/120 [==============================] - 0s 198us/sample - loss: 1.0667 - accuracy: 0.3750 - val_loss: 1.0898 - val_accuracy: 0.4000\n",
      "Epoch 12/300\n",
      "120/120 [==============================] - 0s 214us/sample - loss: 1.0608 - accuracy: 0.4083 - val_loss: 1.0846 - val_accuracy: 0.4000\n",
      "Epoch 13/300\n",
      "120/120 [==============================] - 0s 155us/sample - loss: 1.0555 - accuracy: 0.4333 - val_loss: 1.0793 - val_accuracy: 0.4000\n",
      "Epoch 14/300\n",
      "120/120 [==============================] - 0s 164us/sample - loss: 1.0497 - accuracy: 0.4500 - val_loss: 1.0743 - val_accuracy: 0.4000\n",
      "Epoch 15/300\n",
      "120/120 [==============================] - 0s 232us/sample - loss: 1.0442 - accuracy: 0.4417 - val_loss: 1.0695 - val_accuracy: 0.4000\n",
      "Epoch 16/300\n",
      "120/120 [==============================] - 0s 179us/sample - loss: 1.0392 - accuracy: 0.4500 - val_loss: 1.0645 - val_accuracy: 0.4667\n",
      "Epoch 17/300\n",
      "120/120 [==============================] - 0s 188us/sample - loss: 1.0341 - accuracy: 0.4667 - val_loss: 1.0598 - val_accuracy: 0.4667\n",
      "Epoch 18/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 1.0291 - accuracy: 0.4500 - val_loss: 1.0555 - val_accuracy: 0.5000\n",
      "Epoch 19/300\n",
      "120/120 [==============================] - 0s 204us/sample - loss: 1.0243 - accuracy: 0.4750 - val_loss: 1.0513 - val_accuracy: 0.5333\n",
      "Epoch 20/300\n",
      "120/120 [==============================] - 0s 173us/sample - loss: 1.0191 - accuracy: 0.4750 - val_loss: 1.0473 - val_accuracy: 0.5333\n",
      "Epoch 21/300\n",
      "120/120 [==============================] - 0s 157us/sample - loss: 1.0147 - accuracy: 0.4750 - val_loss: 1.0431 - val_accuracy: 0.5333\n",
      "Epoch 22/300\n",
      "120/120 [==============================] - 0s 148us/sample - loss: 1.0098 - accuracy: 0.4500 - val_loss: 1.0390 - val_accuracy: 0.4667\n",
      "Epoch 23/300\n",
      "120/120 [==============================] - 0s 215us/sample - loss: 1.0051 - accuracy: 0.4500 - val_loss: 1.0348 - val_accuracy: 0.4667\n",
      "Epoch 24/300\n",
      "120/120 [==============================] - 0s 137us/sample - loss: 1.0005 - accuracy: 0.4583 - val_loss: 1.0309 - val_accuracy: 0.4333\n",
      "Epoch 25/300\n",
      "120/120 [==============================] - 0s 186us/sample - loss: 0.9960 - accuracy: 0.4583 - val_loss: 1.0269 - val_accuracy: 0.4000\n",
      "Epoch 26/300\n",
      "120/120 [==============================] - 0s 196us/sample - loss: 0.9912 - accuracy: 0.4417 - val_loss: 1.0230 - val_accuracy: 0.4000\n",
      "Epoch 27/300\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.9865 - accuracy: 0.4500 - val_loss: 1.0190 - val_accuracy: 0.4000\n",
      "Epoch 28/300\n",
      "120/120 [==============================] - 0s 163us/sample - loss: 0.9821 - accuracy: 0.4333 - val_loss: 1.0152 - val_accuracy: 0.4000\n",
      "Epoch 29/300\n",
      "120/120 [==============================] - 0s 222us/sample - loss: 0.9776 - accuracy: 0.4500 - val_loss: 1.0114 - val_accuracy: 0.4000\n",
      "Epoch 30/300\n",
      "120/120 [==============================] - 0s 199us/sample - loss: 0.9731 - accuracy: 0.4750 - val_loss: 1.0075 - val_accuracy: 0.4333\n",
      "Epoch 31/300\n",
      "120/120 [==============================] - 0s 163us/sample - loss: 0.9687 - accuracy: 0.4667 - val_loss: 1.0035 - val_accuracy: 0.4000\n",
      "Epoch 32/300\n",
      "120/120 [==============================] - 0s 196us/sample - loss: 0.9644 - accuracy: 0.4833 - val_loss: 0.9995 - val_accuracy: 0.4000\n",
      "Epoch 33/300\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 0.9597 - accuracy: 0.4833 - val_loss: 0.9957 - val_accuracy: 0.4667\n",
      "Epoch 34/300\n",
      "120/120 [==============================] - 0s 159us/sample - loss: 0.9555 - accuracy: 0.4583 - val_loss: 0.9919 - val_accuracy: 0.4333\n",
      "Epoch 35/300\n",
      "120/120 [==============================] - 0s 159us/sample - loss: 0.9510 - accuracy: 0.4833 - val_loss: 0.9880 - val_accuracy: 0.4333\n",
      "Epoch 36/300\n",
      "120/120 [==============================] - 0s 234us/sample - loss: 0.9464 - accuracy: 0.4917 - val_loss: 0.9843 - val_accuracy: 0.4333\n",
      "Epoch 37/300\n",
      "120/120 [==============================] - 0s 246us/sample - loss: 0.9421 - accuracy: 0.5000 - val_loss: 0.9804 - val_accuracy: 0.4333\n",
      "Epoch 38/300\n",
      "120/120 [==============================] - 0s 280us/sample - loss: 0.9380 - accuracy: 0.5000 - val_loss: 0.9767 - val_accuracy: 0.4333\n",
      "Epoch 39/300\n",
      "120/120 [==============================] - 0s 144us/sample - loss: 0.9334 - accuracy: 0.5083 - val_loss: 0.9728 - val_accuracy: 0.4333\n",
      "Epoch 40/300\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 0.9292 - accuracy: 0.5167 - val_loss: 0.9688 - val_accuracy: 0.4333\n",
      "Epoch 41/300\n",
      "120/120 [==============================] - 0s 231us/sample - loss: 0.9250 - accuracy: 0.5333 - val_loss: 0.9649 - val_accuracy: 0.4333\n",
      "Epoch 42/300\n",
      "120/120 [==============================] - 0s 255us/sample - loss: 0.9204 - accuracy: 0.5417 - val_loss: 0.9611 - val_accuracy: 0.4333\n",
      "Epoch 43/300\n",
      "120/120 [==============================] - 0s 204us/sample - loss: 0.9160 - accuracy: 0.5417 - val_loss: 0.9574 - val_accuracy: 0.4333\n",
      "Epoch 44/300\n",
      "120/120 [==============================] - 0s 222us/sample - loss: 0.9117 - accuracy: 0.5500 - val_loss: 0.9537 - val_accuracy: 0.4000\n",
      "Epoch 45/300\n",
      "120/120 [==============================] - 0s 163us/sample - loss: 0.9074 - accuracy: 0.5667 - val_loss: 0.9500 - val_accuracy: 0.4000\n",
      "Epoch 46/300\n",
      "120/120 [==============================] - 0s 140us/sample - loss: 0.9031 - accuracy: 0.5833 - val_loss: 0.9461 - val_accuracy: 0.4000\n",
      "Epoch 47/300\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.8989 - accuracy: 0.5833 - val_loss: 0.9425 - val_accuracy: 0.4333\n",
      "Epoch 48/300\n",
      "120/120 [==============================] - 0s 173us/sample - loss: 0.8944 - accuracy: 0.6083 - val_loss: 0.9387 - val_accuracy: 0.4333\n",
      "Epoch 49/300\n",
      "120/120 [==============================] - 0s 224us/sample - loss: 0.8900 - accuracy: 0.6083 - val_loss: 0.9349 - val_accuracy: 0.4667\n",
      "Epoch 50/300\n",
      "120/120 [==============================] - 0s 271us/sample - loss: 0.8858 - accuracy: 0.6167 - val_loss: 0.9310 - val_accuracy: 0.4667\n",
      "Epoch 51/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.8817 - accuracy: 0.6167 - val_loss: 0.9272 - val_accuracy: 0.4667\n",
      "Epoch 52/300\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 0.8772 - accuracy: 0.6333 - val_loss: 0.9235 - val_accuracy: 0.4667\n",
      "Epoch 53/300\n",
      "120/120 [==============================] - 0s 300us/sample - loss: 0.8730 - accuracy: 0.6417 - val_loss: 0.9197 - val_accuracy: 0.4667\n",
      "Epoch 54/300\n",
      "120/120 [==============================] - 0s 139us/sample - loss: 0.8687 - accuracy: 0.6583 - val_loss: 0.9160 - val_accuracy: 0.4667\n",
      "Epoch 55/300\n",
      "120/120 [==============================] - 0s 184us/sample - loss: 0.8645 - accuracy: 0.6583 - val_loss: 0.9124 - val_accuracy: 0.4667\n",
      "Epoch 56/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 222us/sample - loss: 0.8602 - accuracy: 0.6583 - val_loss: 0.9087 - val_accuracy: 0.4667\n",
      "Epoch 57/300\n",
      "120/120 [==============================] - 0s 156us/sample - loss: 0.8561 - accuracy: 0.6583 - val_loss: 0.9049 - val_accuracy: 0.5000\n",
      "Epoch 58/300\n",
      "120/120 [==============================] - 0s 220us/sample - loss: 0.8517 - accuracy: 0.6583 - val_loss: 0.9012 - val_accuracy: 0.5000\n",
      "Epoch 59/300\n",
      "120/120 [==============================] - 0s 141us/sample - loss: 0.8475 - accuracy: 0.6583 - val_loss: 0.8977 - val_accuracy: 0.5667\n",
      "Epoch 60/300\n",
      "120/120 [==============================] - 0s 156us/sample - loss: 0.8432 - accuracy: 0.6583 - val_loss: 0.8939 - val_accuracy: 0.5667\n",
      "Epoch 61/300\n",
      "120/120 [==============================] - 0s 149us/sample - loss: 0.8391 - accuracy: 0.6667 - val_loss: 0.8904 - val_accuracy: 0.5667\n",
      "Epoch 62/300\n",
      "120/120 [==============================] - 0s 127us/sample - loss: 0.8350 - accuracy: 0.6667 - val_loss: 0.8866 - val_accuracy: 0.5667\n",
      "Epoch 63/300\n",
      "120/120 [==============================] - 0s 159us/sample - loss: 0.8306 - accuracy: 0.6667 - val_loss: 0.8829 - val_accuracy: 0.6000\n",
      "Epoch 64/300\n",
      "120/120 [==============================] - 0s 166us/sample - loss: 0.8267 - accuracy: 0.6750 - val_loss: 0.8791 - val_accuracy: 0.6000\n",
      "Epoch 65/300\n",
      "120/120 [==============================] - 0s 139us/sample - loss: 0.8226 - accuracy: 0.6750 - val_loss: 0.8755 - val_accuracy: 0.6000\n",
      "Epoch 66/300\n",
      "120/120 [==============================] - 0s 139us/sample - loss: 0.8182 - accuracy: 0.6750 - val_loss: 0.8718 - val_accuracy: 0.6000\n",
      "Epoch 67/300\n",
      "120/120 [==============================] - 0s 185us/sample - loss: 0.8142 - accuracy: 0.6750 - val_loss: 0.8681 - val_accuracy: 0.6000\n",
      "Epoch 68/300\n",
      "120/120 [==============================] - 0s 162us/sample - loss: 0.8102 - accuracy: 0.6750 - val_loss: 0.8644 - val_accuracy: 0.6000\n",
      "Epoch 69/300\n",
      "120/120 [==============================] - 0s 154us/sample - loss: 0.8061 - accuracy: 0.6750 - val_loss: 0.8607 - val_accuracy: 0.6000\n",
      "Epoch 70/300\n",
      "120/120 [==============================] - 0s 174us/sample - loss: 0.8021 - accuracy: 0.6833 - val_loss: 0.8571 - val_accuracy: 0.6000\n",
      "Epoch 71/300\n",
      "120/120 [==============================] - 0s 160us/sample - loss: 0.7979 - accuracy: 0.6833 - val_loss: 0.8536 - val_accuracy: 0.6000\n",
      "Epoch 72/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.7940 - accuracy: 0.6833 - val_loss: 0.8500 - val_accuracy: 0.6000\n",
      "Epoch 73/300\n",
      "120/120 [==============================] - 0s 144us/sample - loss: 0.7899 - accuracy: 0.6833 - val_loss: 0.8464 - val_accuracy: 0.6000\n",
      "Epoch 74/300\n",
      "120/120 [==============================] - 0s 172us/sample - loss: 0.7861 - accuracy: 0.6833 - val_loss: 0.8429 - val_accuracy: 0.6000\n",
      "Epoch 75/300\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.7822 - accuracy: 0.6833 - val_loss: 0.8395 - val_accuracy: 0.6000\n",
      "Epoch 76/300\n",
      "120/120 [==============================] - 0s 154us/sample - loss: 0.7782 - accuracy: 0.6833 - val_loss: 0.8360 - val_accuracy: 0.6000\n",
      "Epoch 77/300\n",
      "120/120 [==============================] - 0s 141us/sample - loss: 0.7743 - accuracy: 0.6833 - val_loss: 0.8324 - val_accuracy: 0.6000\n",
      "Epoch 78/300\n",
      "120/120 [==============================] - 0s 146us/sample - loss: 0.7705 - accuracy: 0.6833 - val_loss: 0.8289 - val_accuracy: 0.6000\n",
      "Epoch 79/300\n",
      "120/120 [==============================] - 0s 146us/sample - loss: 0.7667 - accuracy: 0.6833 - val_loss: 0.8255 - val_accuracy: 0.6000\n",
      "Epoch 80/300\n",
      "120/120 [==============================] - 0s 139us/sample - loss: 0.7628 - accuracy: 0.6833 - val_loss: 0.8220 - val_accuracy: 0.6000\n",
      "Epoch 81/300\n",
      "120/120 [==============================] - 0s 170us/sample - loss: 0.7591 - accuracy: 0.6833 - val_loss: 0.8186 - val_accuracy: 0.6000\n",
      "Epoch 82/300\n",
      "120/120 [==============================] - 0s 170us/sample - loss: 0.7553 - accuracy: 0.6833 - val_loss: 0.8151 - val_accuracy: 0.6000\n",
      "Epoch 83/300\n",
      "120/120 [==============================] - 0s 139us/sample - loss: 0.7516 - accuracy: 0.6833 - val_loss: 0.8117 - val_accuracy: 0.6000\n",
      "Epoch 84/300\n",
      "120/120 [==============================] - 0s 154us/sample - loss: 0.7478 - accuracy: 0.6833 - val_loss: 0.8083 - val_accuracy: 0.6000\n",
      "Epoch 85/300\n",
      "120/120 [==============================] - 0s 162us/sample - loss: 0.7442 - accuracy: 0.6833 - val_loss: 0.8050 - val_accuracy: 0.6000\n",
      "Epoch 86/300\n",
      "120/120 [==============================] - 0s 194us/sample - loss: 0.7405 - accuracy: 0.6833 - val_loss: 0.8016 - val_accuracy: 0.6000\n",
      "Epoch 87/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.7368 - accuracy: 0.6833 - val_loss: 0.7983 - val_accuracy: 0.6000\n",
      "Epoch 88/300\n",
      "120/120 [==============================] - 0s 151us/sample - loss: 0.7332 - accuracy: 0.6833 - val_loss: 0.7949 - val_accuracy: 0.6000\n",
      "Epoch 89/300\n",
      "120/120 [==============================] - 0s 166us/sample - loss: 0.7297 - accuracy: 0.6833 - val_loss: 0.7916 - val_accuracy: 0.6000\n",
      "Epoch 90/300\n",
      "120/120 [==============================] - 0s 153us/sample - loss: 0.7261 - accuracy: 0.6833 - val_loss: 0.7882 - val_accuracy: 0.6000\n",
      "Epoch 91/300\n",
      "120/120 [==============================] - 0s 156us/sample - loss: 0.7226 - accuracy: 0.6833 - val_loss: 0.7849 - val_accuracy: 0.6000\n",
      "Epoch 92/300\n",
      "120/120 [==============================] - 0s 135us/sample - loss: 0.7191 - accuracy: 0.6833 - val_loss: 0.7815 - val_accuracy: 0.6000\n",
      "Epoch 93/300\n",
      "120/120 [==============================] - 0s 173us/sample - loss: 0.7156 - accuracy: 0.6833 - val_loss: 0.7782 - val_accuracy: 0.6000\n",
      "Epoch 94/300\n",
      "120/120 [==============================] - 0s 152us/sample - loss: 0.7120 - accuracy: 0.6833 - val_loss: 0.7750 - val_accuracy: 0.6000\n",
      "Epoch 95/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.7087 - accuracy: 0.6833 - val_loss: 0.7717 - val_accuracy: 0.6000\n",
      "Epoch 96/300\n",
      "120/120 [==============================] - 0s 136us/sample - loss: 0.7052 - accuracy: 0.6833 - val_loss: 0.7685 - val_accuracy: 0.6000\n",
      "Epoch 97/300\n",
      "120/120 [==============================] - 0s 160us/sample - loss: 0.7018 - accuracy: 0.6833 - val_loss: 0.7654 - val_accuracy: 0.6000\n",
      "Epoch 98/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.6985 - accuracy: 0.6833 - val_loss: 0.7622 - val_accuracy: 0.6000\n",
      "Epoch 99/300\n",
      "120/120 [==============================] - 0s 140us/sample - loss: 0.6951 - accuracy: 0.6833 - val_loss: 0.7590 - val_accuracy: 0.6000\n",
      "Epoch 100/300\n",
      "120/120 [==============================] - 0s 140us/sample - loss: 0.6919 - accuracy: 0.6833 - val_loss: 0.7557 - val_accuracy: 0.6000\n",
      "Epoch 101/300\n",
      "120/120 [==============================] - 0s 144us/sample - loss: 0.6886 - accuracy: 0.6833 - val_loss: 0.7527 - val_accuracy: 0.6000\n",
      "Epoch 102/300\n",
      "120/120 [==============================] - 0s 227us/sample - loss: 0.6853 - accuracy: 0.6833 - val_loss: 0.7496 - val_accuracy: 0.6000\n",
      "Epoch 103/300\n",
      "120/120 [==============================] - 0s 156us/sample - loss: 0.6820 - accuracy: 0.6833 - val_loss: 0.7465 - val_accuracy: 0.6000\n",
      "Epoch 104/300\n",
      "120/120 [==============================] - 0s 202us/sample - loss: 0.6788 - accuracy: 0.6833 - val_loss: 0.7435 - val_accuracy: 0.6000\n",
      "Epoch 105/300\n",
      "120/120 [==============================] - 0s 182us/sample - loss: 0.6757 - accuracy: 0.6833 - val_loss: 0.7404 - val_accuracy: 0.6000\n",
      "Epoch 106/300\n",
      "120/120 [==============================] - 0s 166us/sample - loss: 0.6725 - accuracy: 0.6833 - val_loss: 0.7374 - val_accuracy: 0.6000\n",
      "Epoch 107/300\n",
      "120/120 [==============================] - 0s 162us/sample - loss: 0.6694 - accuracy: 0.6833 - val_loss: 0.7345 - val_accuracy: 0.6000\n",
      "Epoch 108/300\n",
      "120/120 [==============================] - 0s 179us/sample - loss: 0.6663 - accuracy: 0.6833 - val_loss: 0.7315 - val_accuracy: 0.6000\n",
      "Epoch 109/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.6633 - accuracy: 0.6833 - val_loss: 0.7285 - val_accuracy: 0.6000\n",
      "Epoch 110/300\n",
      "120/120 [==============================] - 0s 137us/sample - loss: 0.6602 - accuracy: 0.6833 - val_loss: 0.7257 - val_accuracy: 0.6000\n",
      "Epoch 111/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 152us/sample - loss: 0.6571 - accuracy: 0.6833 - val_loss: 0.7228 - val_accuracy: 0.6000\n",
      "Epoch 112/300\n",
      "120/120 [==============================] - 0s 176us/sample - loss: 0.6543 - accuracy: 0.6833 - val_loss: 0.7200 - val_accuracy: 0.6000\n",
      "Epoch 113/300\n",
      "120/120 [==============================] - 0s 144us/sample - loss: 0.6513 - accuracy: 0.6833 - val_loss: 0.7172 - val_accuracy: 0.6000\n",
      "Epoch 114/300\n",
      "120/120 [==============================] - 0s 145us/sample - loss: 0.6483 - accuracy: 0.6833 - val_loss: 0.7144 - val_accuracy: 0.6000\n",
      "Epoch 115/300\n",
      "120/120 [==============================] - 0s 179us/sample - loss: 0.6456 - accuracy: 0.6833 - val_loss: 0.7116 - val_accuracy: 0.6000\n",
      "Epoch 116/300\n",
      "120/120 [==============================] - 0s 162us/sample - loss: 0.6426 - accuracy: 0.6833 - val_loss: 0.7088 - val_accuracy: 0.6000\n",
      "Epoch 117/300\n",
      "120/120 [==============================] - 0s 143us/sample - loss: 0.6397 - accuracy: 0.6833 - val_loss: 0.7061 - val_accuracy: 0.6000\n",
      "Epoch 118/300\n",
      "120/120 [==============================] - 0s 144us/sample - loss: 0.6371 - accuracy: 0.6833 - val_loss: 0.7034 - val_accuracy: 0.6000\n",
      "Epoch 119/300\n",
      "120/120 [==============================] - 0s 190us/sample - loss: 0.6342 - accuracy: 0.6833 - val_loss: 0.7006 - val_accuracy: 0.6000\n",
      "Epoch 120/300\n",
      "120/120 [==============================] - 0s 146us/sample - loss: 0.6314 - accuracy: 0.6833 - val_loss: 0.6978 - val_accuracy: 0.6333\n",
      "Epoch 121/300\n",
      "120/120 [==============================] - 0s 140us/sample - loss: 0.6287 - accuracy: 0.6833 - val_loss: 0.6950 - val_accuracy: 0.6333\n",
      "Epoch 122/300\n",
      "120/120 [==============================] - 0s 168us/sample - loss: 0.6260 - accuracy: 0.6917 - val_loss: 0.6923 - val_accuracy: 0.6333\n",
      "Epoch 123/300\n",
      "120/120 [==============================] - 0s 174us/sample - loss: 0.6233 - accuracy: 0.6917 - val_loss: 0.6896 - val_accuracy: 0.6333\n",
      "Epoch 124/300\n",
      "120/120 [==============================] - 0s 172us/sample - loss: 0.6206 - accuracy: 0.6917 - val_loss: 0.6869 - val_accuracy: 0.6333\n",
      "Epoch 125/300\n",
      "120/120 [==============================] - 0s 167us/sample - loss: 0.6181 - accuracy: 0.6917 - val_loss: 0.6842 - val_accuracy: 0.6333\n",
      "Epoch 126/300\n",
      "120/120 [==============================] - 0s 143us/sample - loss: 0.6154 - accuracy: 0.7000 - val_loss: 0.6816 - val_accuracy: 0.6333\n",
      "Epoch 127/300\n",
      "120/120 [==============================] - 0s 141us/sample - loss: 0.6127 - accuracy: 0.7000 - val_loss: 0.6791 - val_accuracy: 0.6333\n",
      "Epoch 128/300\n",
      "120/120 [==============================] - 0s 151us/sample - loss: 0.6102 - accuracy: 0.7000 - val_loss: 0.6766 - val_accuracy: 0.6333\n",
      "Epoch 129/300\n",
      "120/120 [==============================] - 0s 181us/sample - loss: 0.6077 - accuracy: 0.7000 - val_loss: 0.6741 - val_accuracy: 0.6333\n",
      "Epoch 130/300\n",
      "120/120 [==============================] - 0s 172us/sample - loss: 0.6051 - accuracy: 0.7000 - val_loss: 0.6715 - val_accuracy: 0.6333\n",
      "Epoch 131/300\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.6025 - accuracy: 0.7000 - val_loss: 0.6690 - val_accuracy: 0.6333\n",
      "Epoch 132/300\n",
      "120/120 [==============================] - 0s 134us/sample - loss: 0.6001 - accuracy: 0.7083 - val_loss: 0.6665 - val_accuracy: 0.6333\n",
      "Epoch 133/300\n",
      "120/120 [==============================] - 0s 149us/sample - loss: 0.5976 - accuracy: 0.7083 - val_loss: 0.6640 - val_accuracy: 0.6333\n",
      "Epoch 134/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.5952 - accuracy: 0.7083 - val_loss: 0.6615 - val_accuracy: 0.6333\n",
      "Epoch 135/300\n",
      "120/120 [==============================] - 0s 153us/sample - loss: 0.5927 - accuracy: 0.7083 - val_loss: 0.6590 - val_accuracy: 0.6333\n",
      "Epoch 136/300\n",
      "120/120 [==============================] - 0s 162us/sample - loss: 0.5903 - accuracy: 0.7083 - val_loss: 0.6565 - val_accuracy: 0.6333\n",
      "Epoch 137/300\n",
      "120/120 [==============================] - 0s 164us/sample - loss: 0.5879 - accuracy: 0.7083 - val_loss: 0.6540 - val_accuracy: 0.6333\n",
      "Epoch 138/300\n",
      "120/120 [==============================] - 0s 152us/sample - loss: 0.5855 - accuracy: 0.7083 - val_loss: 0.6515 - val_accuracy: 0.6333\n",
      "Epoch 139/300\n",
      "120/120 [==============================] - 0s 160us/sample - loss: 0.5832 - accuracy: 0.7083 - val_loss: 0.6491 - val_accuracy: 0.6333\n",
      "Epoch 140/300\n",
      "120/120 [==============================] - 0s 169us/sample - loss: 0.5809 - accuracy: 0.7083 - val_loss: 0.6466 - val_accuracy: 0.6333\n",
      "Epoch 141/300\n",
      "120/120 [==============================] - 0s 172us/sample - loss: 0.5785 - accuracy: 0.7083 - val_loss: 0.6443 - val_accuracy: 0.6333\n",
      "Epoch 142/300\n",
      "120/120 [==============================] - 0s 147us/sample - loss: 0.5763 - accuracy: 0.7167 - val_loss: 0.6418 - val_accuracy: 0.6667\n",
      "Epoch 143/300\n",
      "120/120 [==============================] - 0s 131us/sample - loss: 0.5739 - accuracy: 0.7167 - val_loss: 0.6395 - val_accuracy: 0.6667\n",
      "Epoch 144/300\n",
      "120/120 [==============================] - 0s 147us/sample - loss: 0.5717 - accuracy: 0.7167 - val_loss: 0.6372 - val_accuracy: 0.6667\n",
      "Epoch 145/300\n",
      "120/120 [==============================] - 0s 144us/sample - loss: 0.5694 - accuracy: 0.7167 - val_loss: 0.6349 - val_accuracy: 0.6667\n",
      "Epoch 146/300\n",
      "120/120 [==============================] - 0s 126us/sample - loss: 0.5671 - accuracy: 0.7167 - val_loss: 0.6325 - val_accuracy: 0.6667\n",
      "Epoch 147/300\n",
      "120/120 [==============================] - 0s 160us/sample - loss: 0.5648 - accuracy: 0.7167 - val_loss: 0.6301 - val_accuracy: 0.6667\n",
      "Epoch 148/300\n",
      "120/120 [==============================] - 0s 141us/sample - loss: 0.5627 - accuracy: 0.7167 - val_loss: 0.6277 - val_accuracy: 0.6667\n",
      "Epoch 149/300\n",
      "120/120 [==============================] - 0s 129us/sample - loss: 0.5605 - accuracy: 0.7167 - val_loss: 0.6253 - val_accuracy: 0.6667\n",
      "Epoch 150/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.5583 - accuracy: 0.7250 - val_loss: 0.6230 - val_accuracy: 0.6667\n",
      "Epoch 151/300\n",
      "120/120 [==============================] - 0s 182us/sample - loss: 0.5562 - accuracy: 0.7333 - val_loss: 0.6207 - val_accuracy: 0.6667\n",
      "Epoch 152/300\n",
      "120/120 [==============================] - 0s 147us/sample - loss: 0.5541 - accuracy: 0.7333 - val_loss: 0.6184 - val_accuracy: 0.6667\n",
      "Epoch 153/300\n",
      "120/120 [==============================] - 0s 181us/sample - loss: 0.5520 - accuracy: 0.7333 - val_loss: 0.6160 - val_accuracy: 0.6667\n",
      "Epoch 154/300\n",
      "120/120 [==============================] - 0s 240us/sample - loss: 0.5500 - accuracy: 0.7333 - val_loss: 0.6135 - val_accuracy: 0.6667\n",
      "Epoch 155/300\n",
      "120/120 [==============================] - 0s 146us/sample - loss: 0.5478 - accuracy: 0.7333 - val_loss: 0.6113 - val_accuracy: 0.6667\n",
      "Epoch 156/300\n",
      "120/120 [==============================] - 0s 140us/sample - loss: 0.5457 - accuracy: 0.7333 - val_loss: 0.6092 - val_accuracy: 0.6667\n",
      "Epoch 157/300\n",
      "120/120 [==============================] - 0s 155us/sample - loss: 0.5437 - accuracy: 0.7333 - val_loss: 0.6069 - val_accuracy: 0.7333\n",
      "Epoch 158/300\n",
      "120/120 [==============================] - 0s 115us/sample - loss: 0.5417 - accuracy: 0.7417 - val_loss: 0.6045 - val_accuracy: 0.7667\n",
      "Epoch 159/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.5397 - accuracy: 0.7417 - val_loss: 0.6024 - val_accuracy: 0.7667\n",
      "Epoch 160/300\n",
      "120/120 [==============================] - 0s 240us/sample - loss: 0.5377 - accuracy: 0.7417 - val_loss: 0.6003 - val_accuracy: 0.7667\n",
      "Epoch 161/300\n",
      "120/120 [==============================] - 0s 148us/sample - loss: 0.5358 - accuracy: 0.7417 - val_loss: 0.5983 - val_accuracy: 0.7667\n",
      "Epoch 162/300\n",
      "120/120 [==============================] - 0s 123us/sample - loss: 0.5338 - accuracy: 0.7583 - val_loss: 0.5962 - val_accuracy: 0.7667\n",
      "Epoch 163/300\n",
      "120/120 [==============================] - 0s 148us/sample - loss: 0.5319 - accuracy: 0.7583 - val_loss: 0.5941 - val_accuracy: 0.7667\n",
      "Epoch 164/300\n",
      "120/120 [==============================] - 0s 144us/sample - loss: 0.5300 - accuracy: 0.7583 - val_loss: 0.5922 - val_accuracy: 0.7667\n",
      "Epoch 165/300\n",
      "120/120 [==============================] - 0s 161us/sample - loss: 0.5281 - accuracy: 0.7583 - val_loss: 0.5903 - val_accuracy: 0.7667\n",
      "Epoch 166/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 147us/sample - loss: 0.5262 - accuracy: 0.7583 - val_loss: 0.5883 - val_accuracy: 0.7667\n",
      "Epoch 167/300\n",
      "120/120 [==============================] - 0s 130us/sample - loss: 0.5243 - accuracy: 0.7583 - val_loss: 0.5864 - val_accuracy: 0.7667\n",
      "Epoch 168/300\n",
      "120/120 [==============================] - 0s 147us/sample - loss: 0.5226 - accuracy: 0.7583 - val_loss: 0.5843 - val_accuracy: 0.7667\n",
      "Epoch 169/300\n",
      "120/120 [==============================] - 0s 124us/sample - loss: 0.5208 - accuracy: 0.7583 - val_loss: 0.5826 - val_accuracy: 0.7667\n",
      "Epoch 170/300\n",
      "120/120 [==============================] - 0s 141us/sample - loss: 0.5189 - accuracy: 0.7583 - val_loss: 0.5805 - val_accuracy: 0.7667\n",
      "Epoch 171/300\n",
      "120/120 [==============================] - 0s 124us/sample - loss: 0.5171 - accuracy: 0.7750 - val_loss: 0.5787 - val_accuracy: 0.7667\n",
      "Epoch 172/300\n",
      "120/120 [==============================] - 0s 151us/sample - loss: 0.5153 - accuracy: 0.7833 - val_loss: 0.5767 - val_accuracy: 0.7667\n",
      "Epoch 173/300\n",
      "120/120 [==============================] - 0s 141us/sample - loss: 0.5135 - accuracy: 0.7833 - val_loss: 0.5748 - val_accuracy: 0.7667\n",
      "Epoch 174/300\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 0.5118 - accuracy: 0.7917 - val_loss: 0.5729 - val_accuracy: 0.7667\n",
      "Epoch 175/300\n",
      "120/120 [==============================] - 0s 176us/sample - loss: 0.5101 - accuracy: 0.7917 - val_loss: 0.5712 - val_accuracy: 0.7667\n",
      "Epoch 176/300\n",
      "120/120 [==============================] - 0s 172us/sample - loss: 0.5083 - accuracy: 0.7917 - val_loss: 0.5692 - val_accuracy: 0.7667\n",
      "Epoch 177/300\n",
      "120/120 [==============================] - 0s 141us/sample - loss: 0.5066 - accuracy: 0.7917 - val_loss: 0.5673 - val_accuracy: 0.7667\n",
      "Epoch 178/300\n",
      "120/120 [==============================] - 0s 137us/sample - loss: 0.5049 - accuracy: 0.8000 - val_loss: 0.5657 - val_accuracy: 0.7667\n",
      "Epoch 179/300\n",
      "120/120 [==============================] - 0s 145us/sample - loss: 0.5032 - accuracy: 0.8000 - val_loss: 0.5639 - val_accuracy: 0.7667\n",
      "Epoch 180/300\n",
      "120/120 [==============================] - 0s 137us/sample - loss: 0.5015 - accuracy: 0.8000 - val_loss: 0.5621 - val_accuracy: 0.8000\n",
      "Epoch 181/300\n",
      "120/120 [==============================] - 0s 197us/sample - loss: 0.4999 - accuracy: 0.8000 - val_loss: 0.5602 - val_accuracy: 0.8000\n",
      "Epoch 182/300\n",
      "120/120 [==============================] - 0s 168us/sample - loss: 0.4982 - accuracy: 0.8000 - val_loss: 0.5583 - val_accuracy: 0.8000\n",
      "Epoch 183/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.4966 - accuracy: 0.8000 - val_loss: 0.5567 - val_accuracy: 0.8000\n",
      "Epoch 184/300\n",
      "120/120 [==============================] - 0s 156us/sample - loss: 0.4950 - accuracy: 0.8000 - val_loss: 0.5549 - val_accuracy: 0.8000\n",
      "Epoch 185/300\n",
      "120/120 [==============================] - 0s 139us/sample - loss: 0.4934 - accuracy: 0.8083 - val_loss: 0.5531 - val_accuracy: 0.8000\n",
      "Epoch 186/300\n",
      "120/120 [==============================] - 0s 139us/sample - loss: 0.4918 - accuracy: 0.8167 - val_loss: 0.5515 - val_accuracy: 0.8000\n",
      "Epoch 187/300\n",
      "120/120 [==============================] - 0s 128us/sample - loss: 0.4902 - accuracy: 0.8167 - val_loss: 0.5498 - val_accuracy: 0.8000\n",
      "Epoch 188/300\n",
      "120/120 [==============================] - 0s 165us/sample - loss: 0.4887 - accuracy: 0.8167 - val_loss: 0.5479 - val_accuracy: 0.8000\n",
      "Epoch 189/300\n",
      "120/120 [==============================] - 0s 194us/sample - loss: 0.4871 - accuracy: 0.8167 - val_loss: 0.5463 - val_accuracy: 0.8000\n",
      "Epoch 190/300\n",
      "120/120 [==============================] - 0s 143us/sample - loss: 0.4856 - accuracy: 0.8167 - val_loss: 0.5446 - val_accuracy: 0.8000\n",
      "Epoch 191/300\n",
      "120/120 [==============================] - 0s 159us/sample - loss: 0.4840 - accuracy: 0.8167 - val_loss: 0.5428 - val_accuracy: 0.8000\n",
      "Epoch 192/300\n",
      "120/120 [==============================] - 0s 156us/sample - loss: 0.4825 - accuracy: 0.8167 - val_loss: 0.5411 - val_accuracy: 0.8000\n",
      "Epoch 193/300\n",
      "120/120 [==============================] - 0s 162us/sample - loss: 0.4810 - accuracy: 0.8167 - val_loss: 0.5393 - val_accuracy: 0.8000\n",
      "Epoch 194/300\n",
      "120/120 [==============================] - 0s 149us/sample - loss: 0.4794 - accuracy: 0.8250 - val_loss: 0.5376 - val_accuracy: 0.8000\n",
      "Epoch 195/300\n",
      "120/120 [==============================] - 0s 148us/sample - loss: 0.4779 - accuracy: 0.8250 - val_loss: 0.5359 - val_accuracy: 0.8000\n",
      "Epoch 196/300\n",
      "120/120 [==============================] - 0s 253us/sample - loss: 0.4764 - accuracy: 0.8250 - val_loss: 0.5342 - val_accuracy: 0.8000\n",
      "Epoch 197/300\n",
      "120/120 [==============================] - 0s 392us/sample - loss: 0.4750 - accuracy: 0.8250 - val_loss: 0.5327 - val_accuracy: 0.8000\n",
      "Epoch 198/300\n",
      "120/120 [==============================] - 0s 162us/sample - loss: 0.4735 - accuracy: 0.8250 - val_loss: 0.5311 - val_accuracy: 0.8000\n",
      "Epoch 199/300\n",
      "120/120 [==============================] - 0s 179us/sample - loss: 0.4720 - accuracy: 0.8250 - val_loss: 0.5295 - val_accuracy: 0.8000\n",
      "Epoch 200/300\n",
      "120/120 [==============================] - 0s 202us/sample - loss: 0.4707 - accuracy: 0.8250 - val_loss: 0.5276 - val_accuracy: 0.8000\n",
      "Epoch 201/300\n",
      "120/120 [==============================] - 0s 162us/sample - loss: 0.4692 - accuracy: 0.8250 - val_loss: 0.5259 - val_accuracy: 0.8000\n",
      "Epoch 202/300\n",
      "120/120 [==============================] - 0s 371us/sample - loss: 0.4676 - accuracy: 0.8250 - val_loss: 0.5243 - val_accuracy: 0.8000\n",
      "Epoch 203/300\n",
      "120/120 [==============================] - 0s 139us/sample - loss: 0.4662 - accuracy: 0.8333 - val_loss: 0.5227 - val_accuracy: 0.8000\n",
      "Epoch 204/300\n",
      "120/120 [==============================] - 0s 148us/sample - loss: 0.4648 - accuracy: 0.8333 - val_loss: 0.5210 - val_accuracy: 0.8000\n",
      "Epoch 205/300\n",
      "120/120 [==============================] - 0s 134us/sample - loss: 0.4634 - accuracy: 0.8333 - val_loss: 0.5194 - val_accuracy: 0.8000\n",
      "Epoch 206/300\n",
      "120/120 [==============================] - 0s 130us/sample - loss: 0.4620 - accuracy: 0.8333 - val_loss: 0.5179 - val_accuracy: 0.8000\n",
      "Epoch 207/300\n",
      "120/120 [==============================] - 0s 140us/sample - loss: 0.4606 - accuracy: 0.8333 - val_loss: 0.5164 - val_accuracy: 0.8000\n",
      "Epoch 208/300\n",
      "120/120 [==============================] - 0s 135us/sample - loss: 0.4592 - accuracy: 0.8333 - val_loss: 0.5150 - val_accuracy: 0.8000\n",
      "Epoch 209/300\n",
      "120/120 [==============================] - 0s 148us/sample - loss: 0.4579 - accuracy: 0.8333 - val_loss: 0.5135 - val_accuracy: 0.8000\n",
      "Epoch 210/300\n",
      "120/120 [==============================] - 0s 144us/sample - loss: 0.4565 - accuracy: 0.8333 - val_loss: 0.5116 - val_accuracy: 0.8000\n",
      "Epoch 211/300\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 0.4552 - accuracy: 0.8417 - val_loss: 0.5098 - val_accuracy: 0.8000\n",
      "Epoch 212/300\n",
      "120/120 [==============================] - 0s 171us/sample - loss: 0.4538 - accuracy: 0.8417 - val_loss: 0.5079 - val_accuracy: 0.8000\n",
      "Epoch 213/300\n",
      "120/120 [==============================] - 0s 145us/sample - loss: 0.4524 - accuracy: 0.8583 - val_loss: 0.5062 - val_accuracy: 0.8333\n",
      "Epoch 214/300\n",
      "120/120 [==============================] - 0s 148us/sample - loss: 0.4510 - accuracy: 0.8583 - val_loss: 0.5048 - val_accuracy: 0.8333\n",
      "Epoch 215/300\n",
      "120/120 [==============================] - 0s 211us/sample - loss: 0.4497 - accuracy: 0.8583 - val_loss: 0.5032 - val_accuracy: 0.8333\n",
      "Epoch 216/300\n",
      "120/120 [==============================] - 0s 152us/sample - loss: 0.4484 - accuracy: 0.8583 - val_loss: 0.5019 - val_accuracy: 0.8333\n",
      "Epoch 217/300\n",
      "120/120 [==============================] - 0s 143us/sample - loss: 0.4471 - accuracy: 0.8583 - val_loss: 0.5002 - val_accuracy: 0.8333\n",
      "Epoch 218/300\n",
      "120/120 [==============================] - 0s 136us/sample - loss: 0.4457 - accuracy: 0.8583 - val_loss: 0.4988 - val_accuracy: 0.8333\n",
      "Epoch 219/300\n",
      "120/120 [==============================] - 0s 145us/sample - loss: 0.4444 - accuracy: 0.8583 - val_loss: 0.4973 - val_accuracy: 0.8333\n",
      "Epoch 220/300\n",
      "120/120 [==============================] - 0s 132us/sample - loss: 0.4431 - accuracy: 0.8583 - val_loss: 0.4957 - val_accuracy: 0.8333\n",
      "Epoch 221/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 141us/sample - loss: 0.4418 - accuracy: 0.8583 - val_loss: 0.4941 - val_accuracy: 0.8333\n",
      "Epoch 222/300\n",
      "120/120 [==============================] - 0s 188us/sample - loss: 0.4405 - accuracy: 0.8583 - val_loss: 0.4926 - val_accuracy: 0.8333\n",
      "Epoch 223/300\n",
      "120/120 [==============================] - 0s 128us/sample - loss: 0.4393 - accuracy: 0.8583 - val_loss: 0.4911 - val_accuracy: 0.8333\n",
      "Epoch 224/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.4380 - accuracy: 0.8667 - val_loss: 0.4897 - val_accuracy: 0.8333\n",
      "Epoch 225/300\n",
      "120/120 [==============================] - 0s 155us/sample - loss: 0.4367 - accuracy: 0.8750 - val_loss: 0.4882 - val_accuracy: 0.8333\n",
      "Epoch 226/300\n",
      "120/120 [==============================] - 0s 130us/sample - loss: 0.4355 - accuracy: 0.8750 - val_loss: 0.4867 - val_accuracy: 0.8333\n",
      "Epoch 227/300\n",
      "120/120 [==============================] - 0s 147us/sample - loss: 0.4342 - accuracy: 0.8750 - val_loss: 0.4853 - val_accuracy: 0.8333\n",
      "Epoch 228/300\n",
      "120/120 [==============================] - 0s 148us/sample - loss: 0.4330 - accuracy: 0.8750 - val_loss: 0.4840 - val_accuracy: 0.8333\n",
      "Epoch 229/300\n",
      "120/120 [==============================] - 0s 144us/sample - loss: 0.4318 - accuracy: 0.8833 - val_loss: 0.4825 - val_accuracy: 0.8333\n",
      "Epoch 230/300\n",
      "120/120 [==============================] - 0s 124us/sample - loss: 0.4305 - accuracy: 0.8917 - val_loss: 0.4812 - val_accuracy: 0.8333\n",
      "Epoch 231/300\n",
      "120/120 [==============================] - 0s 144us/sample - loss: 0.4293 - accuracy: 0.8917 - val_loss: 0.4799 - val_accuracy: 0.8333\n",
      "Epoch 232/300\n",
      "120/120 [==============================] - 0s 129us/sample - loss: 0.4281 - accuracy: 0.8917 - val_loss: 0.4785 - val_accuracy: 0.8333\n",
      "Epoch 233/300\n",
      "120/120 [==============================] - 0s 168us/sample - loss: 0.4268 - accuracy: 0.8917 - val_loss: 0.4770 - val_accuracy: 0.8333\n",
      "Epoch 234/300\n",
      "120/120 [==============================] - 0s 174us/sample - loss: 0.4256 - accuracy: 0.8917 - val_loss: 0.4757 - val_accuracy: 0.8333\n",
      "Epoch 235/300\n",
      "120/120 [==============================] - 0s 147us/sample - loss: 0.4244 - accuracy: 0.8917 - val_loss: 0.4744 - val_accuracy: 0.8333\n",
      "Epoch 236/300\n",
      "120/120 [==============================] - 0s 157us/sample - loss: 0.4233 - accuracy: 0.8917 - val_loss: 0.4732 - val_accuracy: 0.8333\n",
      "Epoch 237/300\n",
      "120/120 [==============================] - 0s 165us/sample - loss: 0.4221 - accuracy: 0.8917 - val_loss: 0.4718 - val_accuracy: 0.8333\n",
      "Epoch 238/300\n",
      "120/120 [==============================] - 0s 153us/sample - loss: 0.4209 - accuracy: 0.8917 - val_loss: 0.4705 - val_accuracy: 0.8333\n",
      "Epoch 239/300\n",
      "120/120 [==============================] - 0s 163us/sample - loss: 0.4197 - accuracy: 0.8917 - val_loss: 0.4690 - val_accuracy: 0.8667\n",
      "Epoch 240/300\n",
      "120/120 [==============================] - 0s 199us/sample - loss: 0.4185 - accuracy: 0.8917 - val_loss: 0.4677 - val_accuracy: 0.8667\n",
      "Epoch 241/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.4172 - accuracy: 0.8917 - val_loss: 0.4663 - val_accuracy: 0.8667\n",
      "Epoch 242/300\n",
      "120/120 [==============================] - 0s 163us/sample - loss: 0.4161 - accuracy: 0.8917 - val_loss: 0.4650 - val_accuracy: 0.8667\n",
      "Epoch 243/300\n",
      "120/120 [==============================] - 0s 148us/sample - loss: 0.4149 - accuracy: 0.9000 - val_loss: 0.4634 - val_accuracy: 0.8667\n",
      "Epoch 244/300\n",
      "120/120 [==============================] - 0s 134us/sample - loss: 0.4137 - accuracy: 0.9000 - val_loss: 0.4620 - val_accuracy: 0.8667\n",
      "Epoch 245/300\n",
      "120/120 [==============================] - 0s 180us/sample - loss: 0.4126 - accuracy: 0.9000 - val_loss: 0.4605 - val_accuracy: 0.8667\n",
      "Epoch 246/300\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 0.4114 - accuracy: 0.9000 - val_loss: 0.4592 - val_accuracy: 0.8667\n",
      "Epoch 247/300\n",
      "120/120 [==============================] - 0s 167us/sample - loss: 0.4104 - accuracy: 0.9000 - val_loss: 0.4577 - val_accuracy: 0.8667\n",
      "Epoch 248/300\n",
      "120/120 [==============================] - 0s 162us/sample - loss: 0.4091 - accuracy: 0.9000 - val_loss: 0.4566 - val_accuracy: 0.8667\n",
      "Epoch 249/300\n",
      "120/120 [==============================] - 0s 124us/sample - loss: 0.4079 - accuracy: 0.9000 - val_loss: 0.4552 - val_accuracy: 0.8667\n",
      "Epoch 250/300\n",
      "120/120 [==============================] - 0s 201us/sample - loss: 0.4068 - accuracy: 0.9000 - val_loss: 0.4539 - val_accuracy: 0.8667\n",
      "Epoch 251/300\n",
      "120/120 [==============================] - 0s 140us/sample - loss: 0.4056 - accuracy: 0.9000 - val_loss: 0.4526 - val_accuracy: 0.8667\n",
      "Epoch 252/300\n",
      "120/120 [==============================] - 0s 154us/sample - loss: 0.4045 - accuracy: 0.9083 - val_loss: 0.4512 - val_accuracy: 0.8667\n",
      "Epoch 253/300\n",
      "120/120 [==============================] - 0s 154us/sample - loss: 0.4034 - accuracy: 0.9083 - val_loss: 0.4499 - val_accuracy: 0.8667\n",
      "Epoch 254/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.4022 - accuracy: 0.9083 - val_loss: 0.4487 - val_accuracy: 0.8667\n",
      "Epoch 255/300\n",
      "120/120 [==============================] - 0s 190us/sample - loss: 0.4011 - accuracy: 0.9083 - val_loss: 0.4474 - val_accuracy: 0.8667\n",
      "Epoch 256/300\n",
      "120/120 [==============================] - 0s 143us/sample - loss: 0.4000 - accuracy: 0.9083 - val_loss: 0.4461 - val_accuracy: 0.8667\n",
      "Epoch 257/300\n",
      "120/120 [==============================] - 0s 153us/sample - loss: 0.3988 - accuracy: 0.9083 - val_loss: 0.4448 - val_accuracy: 0.8667\n",
      "Epoch 258/300\n",
      "120/120 [==============================] - 0s 162us/sample - loss: 0.3977 - accuracy: 0.9083 - val_loss: 0.4434 - val_accuracy: 0.8667\n",
      "Epoch 259/300\n",
      "120/120 [==============================] - 0s 179us/sample - loss: 0.3966 - accuracy: 0.9083 - val_loss: 0.4420 - val_accuracy: 0.9000\n",
      "Epoch 260/300\n",
      "120/120 [==============================] - 0s 143us/sample - loss: 0.3954 - accuracy: 0.9083 - val_loss: 0.4407 - val_accuracy: 0.9000\n",
      "Epoch 261/300\n",
      "120/120 [==============================] - 0s 159us/sample - loss: 0.3944 - accuracy: 0.9083 - val_loss: 0.4393 - val_accuracy: 0.9000\n",
      "Epoch 262/300\n",
      "120/120 [==============================] - 0s 148us/sample - loss: 0.3932 - accuracy: 0.9167 - val_loss: 0.4380 - val_accuracy: 0.9000\n",
      "Epoch 263/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.3921 - accuracy: 0.9250 - val_loss: 0.4366 - val_accuracy: 0.9000\n",
      "Epoch 264/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.3910 - accuracy: 0.9250 - val_loss: 0.4351 - val_accuracy: 0.9333\n",
      "Epoch 265/300\n",
      "120/120 [==============================] - 0s 165us/sample - loss: 0.3899 - accuracy: 0.9250 - val_loss: 0.4338 - val_accuracy: 0.9333\n",
      "Epoch 266/300\n",
      "120/120 [==============================] - 0s 228us/sample - loss: 0.3888 - accuracy: 0.9250 - val_loss: 0.4327 - val_accuracy: 0.9333\n",
      "Epoch 267/300\n",
      "120/120 [==============================] - 0s 147us/sample - loss: 0.3876 - accuracy: 0.9250 - val_loss: 0.4314 - val_accuracy: 0.9333\n",
      "Epoch 268/300\n",
      "120/120 [==============================] - 0s 161us/sample - loss: 0.3865 - accuracy: 0.9250 - val_loss: 0.4302 - val_accuracy: 0.9333\n",
      "Epoch 269/300\n",
      "120/120 [==============================] - 0s 136us/sample - loss: 0.3855 - accuracy: 0.9250 - val_loss: 0.4288 - val_accuracy: 0.9333\n",
      "Epoch 270/300\n",
      "120/120 [==============================] - 0s 151us/sample - loss: 0.3843 - accuracy: 0.9250 - val_loss: 0.4276 - val_accuracy: 0.9333\n",
      "Epoch 271/300\n",
      "120/120 [==============================] - 0s 139us/sample - loss: 0.3833 - accuracy: 0.9250 - val_loss: 0.4266 - val_accuracy: 0.9333\n",
      "Epoch 272/300\n",
      "120/120 [==============================] - 0s 160us/sample - loss: 0.3822 - accuracy: 0.9250 - val_loss: 0.4252 - val_accuracy: 0.9667\n",
      "Epoch 273/300\n",
      "120/120 [==============================] - 0s 153us/sample - loss: 0.3811 - accuracy: 0.9333 - val_loss: 0.4240 - val_accuracy: 0.9667\n",
      "Epoch 274/300\n",
      "120/120 [==============================] - 0s 160us/sample - loss: 0.3800 - accuracy: 0.9333 - val_loss: 0.4228 - val_accuracy: 0.9667\n",
      "Epoch 275/300\n",
      "120/120 [==============================] - 0s 178us/sample - loss: 0.3790 - accuracy: 0.9333 - val_loss: 0.4216 - val_accuracy: 0.9667\n",
      "Epoch 276/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 124us/sample - loss: 0.3779 - accuracy: 0.9333 - val_loss: 0.4204 - val_accuracy: 0.9667\n",
      "Epoch 277/300\n",
      "120/120 [==============================] - 0s 187us/sample - loss: 0.3768 - accuracy: 0.9333 - val_loss: 0.4192 - val_accuracy: 0.9667\n",
      "Epoch 278/300\n",
      "120/120 [==============================] - 0s 162us/sample - loss: 0.3757 - accuracy: 0.9333 - val_loss: 0.4179 - val_accuracy: 0.9667\n",
      "Epoch 279/300\n",
      "120/120 [==============================] - 0s 203us/sample - loss: 0.3747 - accuracy: 0.9333 - val_loss: 0.4167 - val_accuracy: 0.9667\n",
      "Epoch 280/300\n",
      "120/120 [==============================] - 0s 137us/sample - loss: 0.3736 - accuracy: 0.9333 - val_loss: 0.4153 - val_accuracy: 0.9667\n",
      "Epoch 281/300\n",
      "120/120 [==============================] - 0s 207us/sample - loss: 0.3726 - accuracy: 0.9333 - val_loss: 0.4141 - val_accuracy: 0.9667\n",
      "Epoch 282/300\n",
      "120/120 [==============================] - 0s 147us/sample - loss: 0.3716 - accuracy: 0.9333 - val_loss: 0.4129 - val_accuracy: 0.9667\n",
      "Epoch 283/300\n",
      "120/120 [==============================] - 0s 182us/sample - loss: 0.3705 - accuracy: 0.9333 - val_loss: 0.4117 - val_accuracy: 0.9667\n",
      "Epoch 284/300\n",
      "120/120 [==============================] - 0s 153us/sample - loss: 0.3695 - accuracy: 0.9333 - val_loss: 0.4106 - val_accuracy: 0.9667\n",
      "Epoch 285/300\n",
      "120/120 [==============================] - 0s 126us/sample - loss: 0.3684 - accuracy: 0.9333 - val_loss: 0.4093 - val_accuracy: 0.9667\n",
      "Epoch 286/300\n",
      "120/120 [==============================] - 0s 147us/sample - loss: 0.3675 - accuracy: 0.9333 - val_loss: 0.4082 - val_accuracy: 0.9667\n",
      "Epoch 287/300\n",
      "120/120 [==============================] - 0s 152us/sample - loss: 0.3663 - accuracy: 0.9333 - val_loss: 0.4069 - val_accuracy: 0.9667\n",
      "Epoch 288/300\n",
      "120/120 [==============================] - 0s 144us/sample - loss: 0.3653 - accuracy: 0.9333 - val_loss: 0.4057 - val_accuracy: 0.9667\n",
      "Epoch 289/300\n",
      "120/120 [==============================] - 0s 198us/sample - loss: 0.3642 - accuracy: 0.9333 - val_loss: 0.4044 - val_accuracy: 0.9667\n",
      "Epoch 290/300\n",
      "120/120 [==============================] - 0s 145us/sample - loss: 0.3632 - accuracy: 0.9333 - val_loss: 0.4030 - val_accuracy: 0.9667\n",
      "Epoch 291/300\n",
      "120/120 [==============================] - 0s 144us/sample - loss: 0.3621 - accuracy: 0.9333 - val_loss: 0.4018 - val_accuracy: 0.9667\n",
      "Epoch 292/300\n",
      "120/120 [==============================] - 0s 163us/sample - loss: 0.3611 - accuracy: 0.9250 - val_loss: 0.4004 - val_accuracy: 0.9667\n",
      "Epoch 293/300\n",
      "120/120 [==============================] - 0s 147us/sample - loss: 0.3599 - accuracy: 0.9250 - val_loss: 0.3994 - val_accuracy: 0.9667\n",
      "Epoch 294/300\n",
      "120/120 [==============================] - 0s 172us/sample - loss: 0.3588 - accuracy: 0.9250 - val_loss: 0.3984 - val_accuracy: 0.9667\n",
      "Epoch 295/300\n",
      "120/120 [==============================] - 0s 159us/sample - loss: 0.3577 - accuracy: 0.9250 - val_loss: 0.3974 - val_accuracy: 0.9667\n",
      "Epoch 296/300\n",
      "120/120 [==============================] - 0s 193us/sample - loss: 0.3565 - accuracy: 0.9333 - val_loss: 0.3963 - val_accuracy: 0.9667\n",
      "Epoch 297/300\n",
      "120/120 [==============================] - 0s 209us/sample - loss: 0.3554 - accuracy: 0.9333 - val_loss: 0.3951 - val_accuracy: 0.9667\n",
      "Epoch 298/300\n",
      "120/120 [==============================] - 0s 170us/sample - loss: 0.3542 - accuracy: 0.9333 - val_loss: 0.3941 - val_accuracy: 0.9667\n",
      "Epoch 299/300\n",
      "120/120 [==============================] - 0s 333us/sample - loss: 0.3529 - accuracy: 0.9333 - val_loss: 0.3930 - val_accuracy: 0.9667\n",
      "Epoch 300/300\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.3518 - accuracy: 0.9333 - val_loss: 0.3917 - val_accuracy: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f629c308e90>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_X_train, \n",
    "          y=y_train, \n",
    "          epochs=300,\n",
    "          validation_data=(scaled_X_test, y_test), verbose=1 ,callbacks=[early_stop]         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:16:35.494469Z",
     "start_time": "2020-05-06T20:16:35.479222Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:16:35.985404Z",
     "start_time": "2020-05-06T20:16:35.965742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.132167</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>1.147080</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.125397</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>1.141181</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.118247</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>1.135128</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.111199</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>1.129140</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.104251</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>1.123248</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.356545</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.396323</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.355394</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.395117</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.354183</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.394117</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.392983</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.351828</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.391725</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy  val_loss  val_accuracy\n",
       "0    1.132167  0.316667  1.147080      0.400000\n",
       "1    1.125397  0.316667  1.141181      0.400000\n",
       "2    1.118247  0.316667  1.135128      0.400000\n",
       "3    1.111199  0.316667  1.129140      0.400000\n",
       "4    1.104251  0.316667  1.123248      0.400000\n",
       "..        ...       ...       ...           ...\n",
       "295  0.356545  0.933333  0.396323      0.966667\n",
       "296  0.355394  0.933333  0.395117      0.966667\n",
       "297  0.354183  0.933333  0.394117      0.966667\n",
       "298  0.352941  0.933333  0.392983      0.966667\n",
       "299  0.351828  0.933333  0.391725      0.966667\n",
       "\n",
       "[300 rows x 4 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:16:48.438849Z",
     "start_time": "2020-05-06T20:16:47.971981Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f62841f2250>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:16:58.266237Z",
     "start_time": "2020-05-06T20:16:58.046283Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f625d551450>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['accuracy','val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:17:08.412976Z",
     "start_time": "2020-05-06T20:17:08.363608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3917251527309418, 0.96666664]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(scaled_X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ready Model for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:17:38.095918Z",
     "start_time": "2020-05-06T20:17:38.075393Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = len(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:17:39.178056Z",
     "start_time": "2020-05-06T20:17:39.167140Z"
    }
   },
   "outputs": [],
   "source": [
    "scaled_X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:18:50.057459Z",
     "start_time": "2020-05-06T20:18:50.040032Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=4,activation='relu'))\n",
    "\n",
    "# Last layer for multi-class classification of 3 species\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:19:43.876267Z",
     "start_time": "2020-05-06T20:19:38.686066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150 samples\n",
      "Epoch 1/300\n",
      "150/150 [==============================] - 0s 160us/sample - loss: 0.2491 - accuracy: 0.9467\n",
      "Epoch 2/300\n",
      "150/150 [==============================] - 0s 103us/sample - loss: 0.2485 - accuracy: 0.9467\n",
      "Epoch 3/300\n",
      "150/150 [==============================] - 0s 74us/sample - loss: 0.2482 - accuracy: 0.9533\n",
      "Epoch 4/300\n",
      "150/150 [==============================] - 0s 79us/sample - loss: 0.2477 - accuracy: 0.9533\n",
      "Epoch 5/300\n",
      "150/150 [==============================] - 0s 96us/sample - loss: 0.2473 - accuracy: 0.9467\n",
      "Epoch 6/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.2467 - accuracy: 0.9467\n",
      "Epoch 7/300\n",
      "150/150 [==============================] - 0s 84us/sample - loss: 0.2462 - accuracy: 0.9533\n",
      "Epoch 8/300\n",
      "150/150 [==============================] - 0s 103us/sample - loss: 0.2457 - accuracy: 0.9533\n",
      "Epoch 9/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.2452 - accuracy: 0.9533\n",
      "Epoch 10/300\n",
      "150/150 [==============================] - 0s 128us/sample - loss: 0.2448 - accuracy: 0.9533\n",
      "Epoch 11/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.2442 - accuracy: 0.9533\n",
      "Epoch 12/300\n",
      "150/150 [==============================] - 0s 128us/sample - loss: 0.2438 - accuracy: 0.9533\n",
      "Epoch 13/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2432 - accuracy: 0.9533\n",
      "Epoch 14/300\n",
      "150/150 [==============================] - 0s 111us/sample - loss: 0.2427 - accuracy: 0.9533\n",
      "Epoch 15/300\n",
      "150/150 [==============================] - 0s 99us/sample - loss: 0.2422 - accuracy: 0.9533\n",
      "Epoch 16/300\n",
      "150/150 [==============================] - 0s 102us/sample - loss: 0.2417 - accuracy: 0.9533\n",
      "Epoch 17/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.2413 - accuracy: 0.9533\n",
      "Epoch 18/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.2408 - accuracy: 0.9533\n",
      "Epoch 19/300\n",
      "150/150 [==============================] - 0s 139us/sample - loss: 0.2403 - accuracy: 0.9533\n",
      "Epoch 20/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.2398 - accuracy: 0.9533\n",
      "Epoch 21/300\n",
      "150/150 [==============================] - 0s 104us/sample - loss: 0.2393 - accuracy: 0.9533\n",
      "Epoch 22/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2389 - accuracy: 0.9533\n",
      "Epoch 23/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.2385 - accuracy: 0.9533\n",
      "Epoch 24/300\n",
      "150/150 [==============================] - 0s 63us/sample - loss: 0.2380 - accuracy: 0.9533\n",
      "Epoch 25/300\n",
      "150/150 [==============================] - 0s 170us/sample - loss: 0.2374 - accuracy: 0.9533\n",
      "Epoch 26/300\n",
      "150/150 [==============================] - 0s 96us/sample - loss: 0.2369 - accuracy: 0.9533\n",
      "Epoch 27/300\n",
      "150/150 [==============================] - 0s 105us/sample - loss: 0.2364 - accuracy: 0.9533\n",
      "Epoch 28/300\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.2361 - accuracy: 0.9533\n",
      "Epoch 29/300\n",
      "150/150 [==============================] - 0s 144us/sample - loss: 0.2355 - accuracy: 0.9533\n",
      "Epoch 30/300\n",
      "150/150 [==============================] - 0s 110us/sample - loss: 0.2351 - accuracy: 0.9533\n",
      "Epoch 31/300\n",
      "150/150 [==============================] - 0s 105us/sample - loss: 0.2345 - accuracy: 0.9533\n",
      "Epoch 32/300\n",
      "150/150 [==============================] - 0s 208us/sample - loss: 0.2340 - accuracy: 0.9533\n",
      "Epoch 33/300\n",
      "150/150 [==============================] - 0s 143us/sample - loss: 0.2336 - accuracy: 0.9533\n",
      "Epoch 34/300\n",
      "150/150 [==============================] - 0s 128us/sample - loss: 0.2332 - accuracy: 0.9533\n",
      "Epoch 35/300\n",
      "150/150 [==============================] - 0s 96us/sample - loss: 0.2326 - accuracy: 0.9533\n",
      "Epoch 36/300\n",
      "150/150 [==============================] - 0s 92us/sample - loss: 0.2321 - accuracy: 0.9467\n",
      "Epoch 37/300\n",
      "150/150 [==============================] - 0s 114us/sample - loss: 0.2316 - accuracy: 0.9467\n",
      "Epoch 38/300\n",
      "150/150 [==============================] - 0s 98us/sample - loss: 0.2312 - accuracy: 0.9467\n",
      "Epoch 39/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2307 - accuracy: 0.9467\n",
      "Epoch 40/300\n",
      "150/150 [==============================] - 0s 108us/sample - loss: 0.2303 - accuracy: 0.9467\n",
      "Epoch 41/300\n",
      "150/150 [==============================] - 0s 99us/sample - loss: 0.2300 - accuracy: 0.9467\n",
      "Epoch 42/300\n",
      "150/150 [==============================] - 0s 121us/sample - loss: 0.2293 - accuracy: 0.9533\n",
      "Epoch 43/300\n",
      "150/150 [==============================] - 0s 78us/sample - loss: 0.2289 - accuracy: 0.9533\n",
      "Epoch 44/300\n",
      "150/150 [==============================] - 0s 117us/sample - loss: 0.2284 - accuracy: 0.9467\n",
      "Epoch 45/300\n",
      "150/150 [==============================] - 0s 111us/sample - loss: 0.2280 - accuracy: 0.9467\n",
      "Epoch 46/300\n",
      "150/150 [==============================] - 0s 119us/sample - loss: 0.2275 - accuracy: 0.9467\n",
      "Epoch 47/300\n",
      "150/150 [==============================] - 0s 97us/sample - loss: 0.2270 - accuracy: 0.9467\n",
      "Epoch 48/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.2265 - accuracy: 0.9467\n",
      "Epoch 49/300\n",
      "150/150 [==============================] - 0s 72us/sample - loss: 0.2262 - accuracy: 0.9467\n",
      "Epoch 50/300\n",
      "150/150 [==============================] - 0s 138us/sample - loss: 0.2256 - accuracy: 0.9533\n",
      "Epoch 51/300\n",
      "150/150 [==============================] - 0s 91us/sample - loss: 0.2252 - accuracy: 0.9533\n",
      "Epoch 52/300\n",
      "150/150 [==============================] - 0s 132us/sample - loss: 0.2247 - accuracy: 0.9533\n",
      "Epoch 53/300\n",
      "150/150 [==============================] - 0s 118us/sample - loss: 0.2243 - accuracy: 0.9467\n",
      "Epoch 54/300\n",
      "150/150 [==============================] - 0s 95us/sample - loss: 0.2238 - accuracy: 0.9467\n",
      "Epoch 55/300\n",
      "150/150 [==============================] - 0s 64us/sample - loss: 0.2233 - accuracy: 0.9467\n",
      "Epoch 56/300\n",
      "150/150 [==============================] - 0s 122us/sample - loss: 0.2229 - accuracy: 0.9467\n",
      "Epoch 57/300\n",
      "150/150 [==============================] - 0s 78us/sample - loss: 0.2224 - accuracy: 0.9467\n",
      "Epoch 58/300\n",
      "150/150 [==============================] - 0s 101us/sample - loss: 0.2220 - accuracy: 0.9467\n",
      "Epoch 59/300\n",
      "150/150 [==============================] - 0s 90us/sample - loss: 0.2215 - accuracy: 0.9467\n",
      "Epoch 60/300\n",
      "150/150 [==============================] - 0s 134us/sample - loss: 0.2212 - accuracy: 0.9467\n",
      "Epoch 61/300\n",
      "150/150 [==============================] - 0s 125us/sample - loss: 0.2207 - accuracy: 0.9467\n",
      "Epoch 62/300\n",
      "150/150 [==============================] - 0s 84us/sample - loss: 0.2202 - accuracy: 0.9467\n",
      "Epoch 63/300\n",
      "150/150 [==============================] - 0s 117us/sample - loss: 0.2197 - accuracy: 0.9467\n",
      "Epoch 64/300\n",
      "150/150 [==============================] - 0s 130us/sample - loss: 0.2193 - accuracy: 0.9467\n",
      "Epoch 65/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.2187 - accuracy: 0.9467\n",
      "Epoch 66/300\n",
      "150/150 [==============================] - 0s 164us/sample - loss: 0.2183 - accuracy: 0.9467\n",
      "Epoch 67/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.2179 - accuracy: 0.9467\n",
      "Epoch 68/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.2175 - accuracy: 0.9467\n",
      "Epoch 69/300\n",
      "150/150 [==============================] - 0s 164us/sample - loss: 0.2170 - accuracy: 0.9467\n",
      "Epoch 70/300\n",
      "150/150 [==============================] - 0s 85us/sample - loss: 0.2165 - accuracy: 0.9467\n",
      "Epoch 71/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.2161 - accuracy: 0.9467\n",
      "Epoch 72/300\n",
      "150/150 [==============================] - 0s 83us/sample - loss: 0.2157 - accuracy: 0.9467\n",
      "Epoch 73/300\n",
      "150/150 [==============================] - 0s 147us/sample - loss: 0.2152 - accuracy: 0.9467\n",
      "Epoch 74/300\n",
      "150/150 [==============================] - 0s 130us/sample - loss: 0.2147 - accuracy: 0.9467\n",
      "Epoch 75/300\n",
      "150/150 [==============================] - 0s 177us/sample - loss: 0.2143 - accuracy: 0.9467\n",
      "Epoch 76/300\n",
      "150/150 [==============================] - 0s 101us/sample - loss: 0.2138 - accuracy: 0.9467\n",
      "Epoch 77/300\n",
      "150/150 [==============================] - 0s 118us/sample - loss: 0.2134 - accuracy: 0.9467\n",
      "Epoch 78/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 113us/sample - loss: 0.2130 - accuracy: 0.9533\n",
      "Epoch 79/300\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.2125 - accuracy: 0.9467\n",
      "Epoch 80/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.2121 - accuracy: 0.9467\n",
      "Epoch 81/300\n",
      "150/150 [==============================] - 0s 81us/sample - loss: 0.2116 - accuracy: 0.9467\n",
      "Epoch 82/300\n",
      "150/150 [==============================] - 0s 94us/sample - loss: 0.2112 - accuracy: 0.9467\n",
      "Epoch 83/300\n",
      "150/150 [==============================] - 0s 63us/sample - loss: 0.2108 - accuracy: 0.9467\n",
      "Epoch 84/300\n",
      "150/150 [==============================] - 0s 91us/sample - loss: 0.2103 - accuracy: 0.9467\n",
      "Epoch 85/300\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.2099 - accuracy: 0.9467\n",
      "Epoch 86/300\n",
      "150/150 [==============================] - 0s 83us/sample - loss: 0.2094 - accuracy: 0.9533\n",
      "Epoch 87/300\n",
      "150/150 [==============================] - 0s 97us/sample - loss: 0.2090 - accuracy: 0.9533\n",
      "Epoch 88/300\n",
      "150/150 [==============================] - 0s 95us/sample - loss: 0.2085 - accuracy: 0.9533\n",
      "Epoch 89/300\n",
      "150/150 [==============================] - 0s 89us/sample - loss: 0.2081 - accuracy: 0.9533\n",
      "Epoch 90/300\n",
      "150/150 [==============================] - 0s 98us/sample - loss: 0.2077 - accuracy: 0.9533\n",
      "Epoch 91/300\n",
      "150/150 [==============================] - 0s 96us/sample - loss: 0.2074 - accuracy: 0.9533\n",
      "Epoch 92/300\n",
      "150/150 [==============================] - 0s 91us/sample - loss: 0.2068 - accuracy: 0.9533\n",
      "Epoch 93/300\n",
      "150/150 [==============================] - 0s 90us/sample - loss: 0.2065 - accuracy: 0.9533\n",
      "Epoch 94/300\n",
      "150/150 [==============================] - 0s 118us/sample - loss: 0.2060 - accuracy: 0.9533\n",
      "Epoch 95/300\n",
      "150/150 [==============================] - 0s 91us/sample - loss: 0.2055 - accuracy: 0.9533\n",
      "Epoch 96/300\n",
      "150/150 [==============================] - 0s 109us/sample - loss: 0.2052 - accuracy: 0.9533\n",
      "Epoch 97/300\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.2048 - accuracy: 0.9533\n",
      "Epoch 98/300\n",
      "150/150 [==============================] - 0s 65us/sample - loss: 0.2042 - accuracy: 0.9533\n",
      "Epoch 99/300\n",
      "150/150 [==============================] - 0s 98us/sample - loss: 0.2038 - accuracy: 0.9533\n",
      "Epoch 100/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2034 - accuracy: 0.9533\n",
      "Epoch 101/300\n",
      "150/150 [==============================] - 0s 95us/sample - loss: 0.2030 - accuracy: 0.9533\n",
      "Epoch 102/300\n",
      "150/150 [==============================] - 0s 70us/sample - loss: 0.2025 - accuracy: 0.9533\n",
      "Epoch 103/300\n",
      "150/150 [==============================] - 0s 96us/sample - loss: 0.2021 - accuracy: 0.9600\n",
      "Epoch 104/300\n",
      "150/150 [==============================] - 0s 85us/sample - loss: 0.2017 - accuracy: 0.9600\n",
      "Epoch 105/300\n",
      "150/150 [==============================] - 0s 64us/sample - loss: 0.2013 - accuracy: 0.9600\n",
      "Epoch 106/300\n",
      "150/150 [==============================] - 0s 102us/sample - loss: 0.2008 - accuracy: 0.9533\n",
      "Epoch 107/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.2006 - accuracy: 0.9533\n",
      "Epoch 108/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.2003 - accuracy: 0.9600\n",
      "Epoch 109/300\n",
      "150/150 [==============================] - 0s 70us/sample - loss: 0.1996 - accuracy: 0.9600\n",
      "Epoch 110/300\n",
      "150/150 [==============================] - 0s 115us/sample - loss: 0.1994 - accuracy: 0.9600\n",
      "Epoch 111/300\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.1987 - accuracy: 0.9600\n",
      "Epoch 112/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1983 - accuracy: 0.9600\n",
      "Epoch 113/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.1979 - accuracy: 0.9533\n",
      "Epoch 114/300\n",
      "150/150 [==============================] - 0s 72us/sample - loss: 0.1976 - accuracy: 0.9533\n",
      "Epoch 115/300\n",
      "150/150 [==============================] - 0s 98us/sample - loss: 0.1972 - accuracy: 0.9533\n",
      "Epoch 116/300\n",
      "150/150 [==============================] - 0s 70us/sample - loss: 0.1967 - accuracy: 0.9533\n",
      "Epoch 117/300\n",
      "150/150 [==============================] - 0s 101us/sample - loss: 0.1965 - accuracy: 0.9600\n",
      "Epoch 118/300\n",
      "150/150 [==============================] - 0s 89us/sample - loss: 0.1959 - accuracy: 0.9600\n",
      "Epoch 119/300\n",
      "150/150 [==============================] - 0s 261us/sample - loss: 0.1954 - accuracy: 0.9600\n",
      "Epoch 120/300\n",
      "150/150 [==============================] - 0s 97us/sample - loss: 0.1950 - accuracy: 0.9600\n",
      "Epoch 121/300\n",
      "150/150 [==============================] - 0s 84us/sample - loss: 0.1951 - accuracy: 0.9533\n",
      "Epoch 122/300\n",
      "150/150 [==============================] - 0s 88us/sample - loss: 0.1943 - accuracy: 0.9533\n",
      "Epoch 123/300\n",
      "150/150 [==============================] - 0s 137us/sample - loss: 0.1938 - accuracy: 0.9600\n",
      "Epoch 124/300\n",
      "150/150 [==============================] - 0s 81us/sample - loss: 0.1935 - accuracy: 0.9600\n",
      "Epoch 125/300\n",
      "150/150 [==============================] - 0s 105us/sample - loss: 0.1930 - accuracy: 0.9600\n",
      "Epoch 126/300\n",
      "150/150 [==============================] - 0s 95us/sample - loss: 0.1926 - accuracy: 0.9600\n",
      "Epoch 127/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.1927 - accuracy: 0.9600\n",
      "Epoch 128/300\n",
      "150/150 [==============================] - 0s 104us/sample - loss: 0.1919 - accuracy: 0.9600\n",
      "Epoch 129/300\n",
      "150/150 [==============================] - 0s 101us/sample - loss: 0.1915 - accuracy: 0.9600\n",
      "Epoch 130/300\n",
      "150/150 [==============================] - 0s 75us/sample - loss: 0.1910 - accuracy: 0.9600\n",
      "Epoch 131/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.1907 - accuracy: 0.9600\n",
      "Epoch 132/300\n",
      "150/150 [==============================] - 0s 82us/sample - loss: 0.1902 - accuracy: 0.9600\n",
      "Epoch 133/300\n",
      "150/150 [==============================] - 0s 63us/sample - loss: 0.1899 - accuracy: 0.9600\n",
      "Epoch 134/300\n",
      "150/150 [==============================] - 0s 109us/sample - loss: 0.1895 - accuracy: 0.9600\n",
      "Epoch 135/300\n",
      "150/150 [==============================] - 0s 68us/sample - loss: 0.1891 - accuracy: 0.9600\n",
      "Epoch 136/300\n",
      "150/150 [==============================] - 0s 134us/sample - loss: 0.1887 - accuracy: 0.9600\n",
      "Epoch 137/300\n",
      "150/150 [==============================] - 0s 83us/sample - loss: 0.1884 - accuracy: 0.9600\n",
      "Epoch 138/300\n",
      "150/150 [==============================] - 0s 115us/sample - loss: 0.1879 - accuracy: 0.9600\n",
      "Epoch 139/300\n",
      "150/150 [==============================] - 0s 101us/sample - loss: 0.1875 - accuracy: 0.9600\n",
      "Epoch 140/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.1872 - accuracy: 0.9600\n",
      "Epoch 141/300\n",
      "150/150 [==============================] - 0s 81us/sample - loss: 0.1868 - accuracy: 0.9600\n",
      "Epoch 142/300\n",
      "150/150 [==============================] - 0s 108us/sample - loss: 0.1865 - accuracy: 0.9600\n",
      "Epoch 143/300\n",
      "150/150 [==============================] - 0s 104us/sample - loss: 0.1860 - accuracy: 0.9600\n",
      "Epoch 144/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.1857 - accuracy: 0.9600\n",
      "Epoch 145/300\n",
      "150/150 [==============================] - 0s 103us/sample - loss: 0.1853 - accuracy: 0.9600\n",
      "Epoch 146/300\n",
      "150/150 [==============================] - 0s 78us/sample - loss: 0.1849 - accuracy: 0.9600\n",
      "Epoch 147/300\n",
      "150/150 [==============================] - 0s 94us/sample - loss: 0.1845 - accuracy: 0.9600\n",
      "Epoch 148/300\n",
      "150/150 [==============================] - 0s 196us/sample - loss: 0.1841 - accuracy: 0.9600\n",
      "Epoch 149/300\n",
      "150/150 [==============================] - 0s 103us/sample - loss: 0.1838 - accuracy: 0.9533\n",
      "Epoch 150/300\n",
      "150/150 [==============================] - 0s 121us/sample - loss: 0.1834 - accuracy: 0.9533\n",
      "Epoch 151/300\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.1832 - accuracy: 0.9533\n",
      "Epoch 152/300\n",
      "150/150 [==============================] - 0s 81us/sample - loss: 0.1826 - accuracy: 0.9600\n",
      "Epoch 153/300\n",
      "150/150 [==============================] - 0s 74us/sample - loss: 0.1823 - accuracy: 0.9533\n",
      "Epoch 154/300\n",
      "150/150 [==============================] - 0s 94us/sample - loss: 0.1819 - accuracy: 0.9533\n",
      "Epoch 155/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 119us/sample - loss: 0.1817 - accuracy: 0.9600\n",
      "Epoch 156/300\n",
      "150/150 [==============================] - 0s 88us/sample - loss: 0.1813 - accuracy: 0.9600\n",
      "Epoch 157/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.1808 - accuracy: 0.9600\n",
      "Epoch 158/300\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.1807 - accuracy: 0.9600\n",
      "Epoch 159/300\n",
      "150/150 [==============================] - 0s 111us/sample - loss: 0.1802 - accuracy: 0.9600\n",
      "Epoch 160/300\n",
      "150/150 [==============================] - 0s 78us/sample - loss: 0.1797 - accuracy: 0.9600\n",
      "Epoch 161/300\n",
      "150/150 [==============================] - 0s 83us/sample - loss: 0.1793 - accuracy: 0.9600\n",
      "Epoch 162/300\n",
      "150/150 [==============================] - 0s 112us/sample - loss: 0.1790 - accuracy: 0.9600\n",
      "Epoch 163/300\n",
      "150/150 [==============================] - 0s 101us/sample - loss: 0.1788 - accuracy: 0.9533\n",
      "Epoch 164/300\n",
      "150/150 [==============================] - 0s 115us/sample - loss: 0.1783 - accuracy: 0.9533\n",
      "Epoch 165/300\n",
      "150/150 [==============================] - 0s 101us/sample - loss: 0.1779 - accuracy: 0.9600\n",
      "Epoch 166/300\n",
      "150/150 [==============================] - 0s 91us/sample - loss: 0.1776 - accuracy: 0.9600\n",
      "Epoch 167/300\n",
      "150/150 [==============================] - 0s 89us/sample - loss: 0.1773 - accuracy: 0.9600\n",
      "Epoch 168/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.1770 - accuracy: 0.9600\n",
      "Epoch 169/300\n",
      "150/150 [==============================] - 0s 88us/sample - loss: 0.1765 - accuracy: 0.9600\n",
      "Epoch 170/300\n",
      "150/150 [==============================] - 0s 82us/sample - loss: 0.1764 - accuracy: 0.9600\n",
      "Epoch 171/300\n",
      "150/150 [==============================] - 0s 75us/sample - loss: 0.1758 - accuracy: 0.9600\n",
      "Epoch 172/300\n",
      "150/150 [==============================] - 0s 99us/sample - loss: 0.1755 - accuracy: 0.9600\n",
      "Epoch 173/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.1751 - accuracy: 0.9600\n",
      "Epoch 174/300\n",
      "150/150 [==============================] - 0s 99us/sample - loss: 0.1747 - accuracy: 0.9600\n",
      "Epoch 175/300\n",
      "150/150 [==============================] - 0s 99us/sample - loss: 0.1744 - accuracy: 0.9600\n",
      "Epoch 176/300\n",
      "150/150 [==============================] - 0s 84us/sample - loss: 0.1741 - accuracy: 0.9600\n",
      "Epoch 177/300\n",
      "150/150 [==============================] - 0s 84us/sample - loss: 0.1737 - accuracy: 0.9600\n",
      "Epoch 178/300\n",
      "150/150 [==============================] - 0s 79us/sample - loss: 0.1734 - accuracy: 0.9600\n",
      "Epoch 179/300\n",
      "150/150 [==============================] - 0s 114us/sample - loss: 0.1730 - accuracy: 0.9600\n",
      "Epoch 180/300\n",
      "150/150 [==============================] - 0s 91us/sample - loss: 0.1727 - accuracy: 0.9600\n",
      "Epoch 181/300\n",
      "150/150 [==============================] - 0s 96us/sample - loss: 0.1723 - accuracy: 0.9600\n",
      "Epoch 182/300\n",
      "150/150 [==============================] - 0s 82us/sample - loss: 0.1720 - accuracy: 0.9600\n",
      "Epoch 183/300\n",
      "150/150 [==============================] - 0s 104us/sample - loss: 0.1717 - accuracy: 0.9600\n",
      "Epoch 184/300\n",
      "150/150 [==============================] - 0s 96us/sample - loss: 0.1713 - accuracy: 0.9600\n",
      "Epoch 185/300\n",
      "150/150 [==============================] - 0s 83us/sample - loss: 0.1709 - accuracy: 0.9600\n",
      "Epoch 186/300\n",
      "150/150 [==============================] - 0s 83us/sample - loss: 0.1706 - accuracy: 0.9600\n",
      "Epoch 187/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1703 - accuracy: 0.9600\n",
      "Epoch 188/300\n",
      "150/150 [==============================] - 0s 63us/sample - loss: 0.1699 - accuracy: 0.9600\n",
      "Epoch 189/300\n",
      "150/150 [==============================] - 0s 102us/sample - loss: 0.1696 - accuracy: 0.9533\n",
      "Epoch 190/300\n",
      "150/150 [==============================] - 0s 69us/sample - loss: 0.1693 - accuracy: 0.9533\n",
      "Epoch 191/300\n",
      "150/150 [==============================] - 0s 79us/sample - loss: 0.1689 - accuracy: 0.9533\n",
      "Epoch 192/300\n",
      "150/150 [==============================] - 0s 129us/sample - loss: 0.1686 - accuracy: 0.9533\n",
      "Epoch 193/300\n",
      "150/150 [==============================] - 0s 101us/sample - loss: 0.1685 - accuracy: 0.9533\n",
      "Epoch 194/300\n",
      "150/150 [==============================] - 0s 103us/sample - loss: 0.1679 - accuracy: 0.9600\n",
      "Epoch 195/300\n",
      "150/150 [==============================] - 0s 90us/sample - loss: 0.1676 - accuracy: 0.9600\n",
      "Epoch 196/300\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1675 - accuracy: 0.9533\n",
      "Epoch 197/300\n",
      "150/150 [==============================] - 0s 84us/sample - loss: 0.1670 - accuracy: 0.9600\n",
      "Epoch 198/300\n",
      "150/150 [==============================] - 0s 103us/sample - loss: 0.1666 - accuracy: 0.9600\n",
      "Epoch 199/300\n",
      "150/150 [==============================] - 0s 105us/sample - loss: 0.1664 - accuracy: 0.9600\n",
      "Epoch 200/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.1661 - accuracy: 0.9600\n",
      "Epoch 201/300\n",
      "150/150 [==============================] - 0s 98us/sample - loss: 0.1657 - accuracy: 0.9600\n",
      "Epoch 202/300\n",
      "150/150 [==============================] - 0s 111us/sample - loss: 0.1653 - accuracy: 0.9600\n",
      "Epoch 203/300\n",
      "150/150 [==============================] - 0s 84us/sample - loss: 0.1651 - accuracy: 0.9600\n",
      "Epoch 204/300\n",
      "150/150 [==============================] - 0s 95us/sample - loss: 0.1649 - accuracy: 0.9533\n",
      "Epoch 205/300\n",
      "150/150 [==============================] - 0s 82us/sample - loss: 0.1645 - accuracy: 0.9600\n",
      "Epoch 206/300\n",
      "150/150 [==============================] - 0s 83us/sample - loss: 0.1642 - accuracy: 0.9600\n",
      "Epoch 207/300\n",
      "150/150 [==============================] - 0s 102us/sample - loss: 0.1638 - accuracy: 0.9600\n",
      "Epoch 208/300\n",
      "150/150 [==============================] - 0s 89us/sample - loss: 0.1635 - accuracy: 0.9600\n",
      "Epoch 209/300\n",
      "150/150 [==============================] - 0s 115us/sample - loss: 0.1631 - accuracy: 0.9600\n",
      "Epoch 210/300\n",
      "150/150 [==============================] - 0s 85us/sample - loss: 0.1628 - accuracy: 0.9600\n",
      "Epoch 211/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1625 - accuracy: 0.9600\n",
      "Epoch 212/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1624 - accuracy: 0.9600\n",
      "Epoch 213/300\n",
      "150/150 [==============================] - 0s 130us/sample - loss: 0.1619 - accuracy: 0.9600\n",
      "Epoch 214/300\n",
      "150/150 [==============================] - 0s 98us/sample - loss: 0.1615 - accuracy: 0.9600\n",
      "Epoch 215/300\n",
      "150/150 [==============================] - 0s 111us/sample - loss: 0.1613 - accuracy: 0.9600\n",
      "Epoch 216/300\n",
      "150/150 [==============================] - 0s 89us/sample - loss: 0.1609 - accuracy: 0.9600\n",
      "Epoch 217/300\n",
      "150/150 [==============================] - 0s 92us/sample - loss: 0.1606 - accuracy: 0.9600\n",
      "Epoch 218/300\n",
      "150/150 [==============================] - 0s 76us/sample - loss: 0.1603 - accuracy: 0.9600\n",
      "Epoch 219/300\n",
      "150/150 [==============================] - 0s 61us/sample - loss: 0.1600 - accuracy: 0.9600\n",
      "Epoch 220/300\n",
      "150/150 [==============================] - 0s 83us/sample - loss: 0.1597 - accuracy: 0.9600\n",
      "Epoch 221/300\n",
      "150/150 [==============================] - 0s 84us/sample - loss: 0.1594 - accuracy: 0.9600\n",
      "Epoch 222/300\n",
      "150/150 [==============================] - 0s 109us/sample - loss: 0.1591 - accuracy: 0.9600\n",
      "Epoch 223/300\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.1588 - accuracy: 0.9600\n",
      "Epoch 224/300\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.1586 - accuracy: 0.9600\n",
      "Epoch 225/300\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.1582 - accuracy: 0.9600\n",
      "Epoch 226/300\n",
      "150/150 [==============================] - 0s 82us/sample - loss: 0.1579 - accuracy: 0.9600\n",
      "Epoch 227/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.1577 - accuracy: 0.9600\n",
      "Epoch 228/300\n",
      "150/150 [==============================] - 0s 75us/sample - loss: 0.1573 - accuracy: 0.9600\n",
      "Epoch 229/300\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.1570 - accuracy: 0.9600\n",
      "Epoch 230/300\n",
      "150/150 [==============================] - 0s 74us/sample - loss: 0.1568 - accuracy: 0.9600\n",
      "Epoch 231/300\n",
      "150/150 [==============================] - 0s 85us/sample - loss: 0.1566 - accuracy: 0.9600\n",
      "Epoch 232/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 111us/sample - loss: 0.1562 - accuracy: 0.9600\n",
      "Epoch 233/300\n",
      "150/150 [==============================] - 0s 122us/sample - loss: 0.1560 - accuracy: 0.9600\n",
      "Epoch 234/300\n",
      "150/150 [==============================] - 0s 111us/sample - loss: 0.1555 - accuracy: 0.9600\n",
      "Epoch 235/300\n",
      "150/150 [==============================] - 0s 104us/sample - loss: 0.1552 - accuracy: 0.9600\n",
      "Epoch 236/300\n",
      "150/150 [==============================] - 0s 174us/sample - loss: 0.1549 - accuracy: 0.9600\n",
      "Epoch 237/300\n",
      "150/150 [==============================] - 0s 105us/sample - loss: 0.1546 - accuracy: 0.9600\n",
      "Epoch 238/300\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1543 - accuracy: 0.9600\n",
      "Epoch 239/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.1541 - accuracy: 0.9600\n",
      "Epoch 240/300\n",
      "150/150 [==============================] - 0s 132us/sample - loss: 0.1537 - accuracy: 0.9600\n",
      "Epoch 241/300\n",
      "150/150 [==============================] - 0s 132us/sample - loss: 0.1535 - accuracy: 0.9600\n",
      "Epoch 242/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1532 - accuracy: 0.9600\n",
      "Epoch 243/300\n",
      "150/150 [==============================] - 0s 170us/sample - loss: 0.1531 - accuracy: 0.9600\n",
      "Epoch 244/300\n",
      "150/150 [==============================] - 0s 89us/sample - loss: 0.1528 - accuracy: 0.9600\n",
      "Epoch 245/300\n",
      "150/150 [==============================] - 0s 103us/sample - loss: 0.1524 - accuracy: 0.9600\n",
      "Epoch 246/300\n",
      "150/150 [==============================] - 0s 98us/sample - loss: 0.1520 - accuracy: 0.9600\n",
      "Epoch 247/300\n",
      "150/150 [==============================] - 0s 103us/sample - loss: 0.1518 - accuracy: 0.9533\n",
      "Epoch 248/300\n",
      "150/150 [==============================] - 0s 146us/sample - loss: 0.1515 - accuracy: 0.9533\n",
      "Epoch 249/300\n",
      "150/150 [==============================] - 0s 82us/sample - loss: 0.1512 - accuracy: 0.9533\n",
      "Epoch 250/300\n",
      "150/150 [==============================] - 0s 122us/sample - loss: 0.1510 - accuracy: 0.9533\n",
      "Epoch 251/300\n",
      "150/150 [==============================] - 0s 85us/sample - loss: 0.1506 - accuracy: 0.9600\n",
      "Epoch 252/300\n",
      "150/150 [==============================] - 0s 171us/sample - loss: 0.1505 - accuracy: 0.9600\n",
      "Epoch 253/300\n",
      "150/150 [==============================] - 0s 130us/sample - loss: 0.1501 - accuracy: 0.9600\n",
      "Epoch 254/300\n",
      "150/150 [==============================] - 0s 123us/sample - loss: 0.1498 - accuracy: 0.9600\n",
      "Epoch 255/300\n",
      "150/150 [==============================] - 0s 178us/sample - loss: 0.1495 - accuracy: 0.9600\n",
      "Epoch 256/300\n",
      "150/150 [==============================] - 0s 84us/sample - loss: 0.1494 - accuracy: 0.9600\n",
      "Epoch 257/300\n",
      "150/150 [==============================] - 0s 119us/sample - loss: 0.1489 - accuracy: 0.9600\n",
      "Epoch 258/300\n",
      "150/150 [==============================] - 0s 88us/sample - loss: 0.1487 - accuracy: 0.9600\n",
      "Epoch 259/300\n",
      "150/150 [==============================] - 0s 405us/sample - loss: 0.1484 - accuracy: 0.9600\n",
      "Epoch 260/300\n",
      "150/150 [==============================] - 0s 164us/sample - loss: 0.1481 - accuracy: 0.9600\n",
      "Epoch 261/300\n",
      "150/150 [==============================] - 0s 75us/sample - loss: 0.1480 - accuracy: 0.9600\n",
      "Epoch 262/300\n",
      "150/150 [==============================] - 0s 139us/sample - loss: 0.1477 - accuracy: 0.9600\n",
      "Epoch 263/300\n",
      "150/150 [==============================] - 0s 115us/sample - loss: 0.1473 - accuracy: 0.9600\n",
      "Epoch 264/300\n",
      "150/150 [==============================] - 0s 104us/sample - loss: 0.1470 - accuracy: 0.9600\n",
      "Epoch 265/300\n",
      "150/150 [==============================] - 0s 123us/sample - loss: 0.1468 - accuracy: 0.9600\n",
      "Epoch 266/300\n",
      "150/150 [==============================] - 0s 170us/sample - loss: 0.1465 - accuracy: 0.9600\n",
      "Epoch 267/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.1465 - accuracy: 0.9600\n",
      "Epoch 268/300\n",
      "150/150 [==============================] - 0s 96us/sample - loss: 0.1460 - accuracy: 0.9600\n",
      "Epoch 269/300\n",
      "150/150 [==============================] - 0s 76us/sample - loss: 0.1458 - accuracy: 0.9600\n",
      "Epoch 270/300\n",
      "150/150 [==============================] - 0s 109us/sample - loss: 0.1456 - accuracy: 0.9600\n",
      "Epoch 271/300\n",
      "150/150 [==============================] - 0s 62us/sample - loss: 0.1452 - accuracy: 0.9600\n",
      "Epoch 272/300\n",
      "150/150 [==============================] - 0s 56us/sample - loss: 0.1449 - accuracy: 0.9600\n",
      "Epoch 273/300\n",
      "150/150 [==============================] - 0s 81us/sample - loss: 0.1446 - accuracy: 0.9600\n",
      "Epoch 274/300\n",
      "150/150 [==============================] - 0s 88us/sample - loss: 0.1444 - accuracy: 0.9600\n",
      "Epoch 275/300\n",
      "150/150 [==============================] - 0s 130us/sample - loss: 0.1441 - accuracy: 0.9600\n",
      "Epoch 276/300\n",
      "150/150 [==============================] - 0s 92us/sample - loss: 0.1440 - accuracy: 0.9600\n",
      "Epoch 277/300\n",
      "150/150 [==============================] - 0s 219us/sample - loss: 0.1436 - accuracy: 0.9600\n",
      "Epoch 278/300\n",
      "150/150 [==============================] - 0s 83us/sample - loss: 0.1433 - accuracy: 0.9600\n",
      "Epoch 279/300\n",
      "150/150 [==============================] - 0s 110us/sample - loss: 0.1431 - accuracy: 0.9600\n",
      "Epoch 280/300\n",
      "150/150 [==============================] - 0s 116us/sample - loss: 0.1429 - accuracy: 0.9600\n",
      "Epoch 281/300\n",
      "150/150 [==============================] - 0s 114us/sample - loss: 0.1426 - accuracy: 0.9600\n",
      "Epoch 282/300\n",
      "150/150 [==============================] - 0s 112us/sample - loss: 0.1426 - accuracy: 0.9600\n",
      "Epoch 283/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.1421 - accuracy: 0.9533\n",
      "Epoch 284/300\n",
      "150/150 [==============================] - 0s 108us/sample - loss: 0.1419 - accuracy: 0.9533\n",
      "Epoch 285/300\n",
      "150/150 [==============================] - 0s 83us/sample - loss: 0.1416 - accuracy: 0.9600\n",
      "Epoch 286/300\n",
      "150/150 [==============================] - 0s 99us/sample - loss: 0.1413 - accuracy: 0.9600\n",
      "Epoch 287/300\n",
      "150/150 [==============================] - 0s 97us/sample - loss: 0.1411 - accuracy: 0.9600\n",
      "Epoch 288/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1408 - accuracy: 0.9600\n",
      "Epoch 289/300\n",
      "150/150 [==============================] - 0s 99us/sample - loss: 0.1407 - accuracy: 0.9600\n",
      "Epoch 290/300\n",
      "150/150 [==============================] - 0s 84us/sample - loss: 0.1404 - accuracy: 0.9600\n",
      "Epoch 291/300\n",
      "150/150 [==============================] - 0s 138us/sample - loss: 0.1402 - accuracy: 0.9600\n",
      "Epoch 292/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.1399 - accuracy: 0.9600\n",
      "Epoch 293/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.1397 - accuracy: 0.9600\n",
      "Epoch 294/300\n",
      "150/150 [==============================] - 0s 70us/sample - loss: 0.1394 - accuracy: 0.9600\n",
      "Epoch 295/300\n",
      "150/150 [==============================] - 0s 90us/sample - loss: 0.1392 - accuracy: 0.9600\n",
      "Epoch 296/300\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1491 - accuracy: 0.96 - 0s 108us/sample - loss: 0.1389 - accuracy: 0.9600\n",
      "Epoch 297/300\n",
      "150/150 [==============================] - 0s 71us/sample - loss: 0.1387 - accuracy: 0.9600\n",
      "Epoch 298/300\n",
      "150/150 [==============================] - 0s 128us/sample - loss: 0.1385 - accuracy: 0.9600\n",
      "Epoch 299/300\n",
      "150/150 [==============================] - 0s 79us/sample - loss: 0.1382 - accuracy: 0.9600\n",
      "Epoch 300/300\n",
      "150/150 [==============================] - 0s 162us/sample - loss: 0.1379 - accuracy: 0.9600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f629c343690>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X,y,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:20:01.894753Z",
     "start_time": "2020-05-06T20:20:01.861335Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"final_iris_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:20:29.416260Z",
     "start_time": "2020-05-06T20:20:29.409490Z"
    }
   },
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:20:38.549176Z",
     "start_time": "2020-05-06T20:20:38.535792Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iris_scaler.pkl']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler,'iris_scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting a Single New Flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:21:22.894158Z",
     "start_time": "2020-05-06T20:21:22.881449Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:21:38.395524Z",
     "start_time": "2020-05-06T20:21:38.355508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "flower_model = load_model(\"final_iris_model.h5\")\n",
    "flower_scaler = joblib.load(\"iris_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:23:33.284883Z",
     "start_time": "2020-05-06T20:23:33.273649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:23:37.266836Z",
     "start_time": "2020-05-06T20:23:37.260871Z"
    }
   },
   "outputs": [],
   "source": [
    "flower_example = {'sepal_length':5.1,\n",
    "                 'sepal_width':3.5,\n",
    "                 'petal_length':1.4,\n",
    "                 'petal_width':0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flower_example.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:29:14.453963Z",
     "start_time": "2020-05-06T20:29:14.442870Z"
    }
   },
   "outputs": [],
   "source": [
    "def return_prediction(model,scaler,sample_json):\n",
    "    \n",
    "    # For larger data features, you should probably write a for loop\n",
    "    # That builds out this array for you\n",
    "    \n",
    "    s_len = sample_json['sepal_length']\n",
    "    s_wid = sample_json['sepal_width']\n",
    "    p_len = sample_json['petal_length']\n",
    "    p_wid = sample_json['petal_width']\n",
    "    \n",
    "    flower = [[s_len,s_wid,p_len,p_wid]]\n",
    "    \n",
    "    flower = scaler.transform(flower)\n",
    "    \n",
    "    classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
    "    \n",
    "    class_ind = model.predict_classes(flower)\n",
    "    \n",
    "    return classes[class_ind][0]\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:29:15.208534Z",
     "start_time": "2020-05-06T20:29:15.153864Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'setosa'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_prediction(flower_model,flower_scaler,flower_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE FOR DEPLOYMENT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "\n",
    "flower_model = load_model(\"final_iris_model.h5\")\n",
    "flower_scaler = joblib.load(\"iris_scaler.pkl\")\n",
    "\n",
    "\n",
    "def return_prediction(model,scaler,sample_json):\n",
    "    \n",
    "    # For larger data features, you should probably write a for loop\n",
    "    # That builds out this array for you\n",
    "    \n",
    "    s_len = sample_json['sepal_length']\n",
    "    s_wid = sample_json['sepal_width']\n",
    "    p_len = sample_json['petal_length']\n",
    "    p_wid = sample_json['petal_width']\n",
    "    \n",
    "    flower = [[s_len,s_wid,p_len,p_wid]]\n",
    "    \n",
    "    flower = scaler.transform(flower)\n",
    "    \n",
    "    classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
    "    \n",
    "    class_ind = model.predict_classes(flower)\n",
    "    \n",
    "    return classes[class_ind][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_example = {\n",
    "\"sepal_length\":5.1,\n",
    "\"sepal_width\":3.5,\n",
    "\"petal_length\":1.4,\n",
    "\"petal_width\":0.2\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
